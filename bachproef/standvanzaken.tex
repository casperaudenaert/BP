\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

%Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

%Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz.\ naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin (narratieve referentie), gebruik je \texttt{$\backslash${}textcite\{\}}. Soms is de auteursnaam niet expliciet een onderdeel van de zin, dan gebruik je \texttt{$\backslash${}autocite\{\}} (referentie tussen haakjes). Dit gebruik je bv.~bij een citaat, of om in het bijschrift van een overgenomen afbeelding, broncode, tabel, enz. te verwijzen naar de bron. In de volgende paragraaf een voorbeeld van elk.

%\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

%Let er ook op: het \texttt{cite}-commando voor de punt, dus binnen de zin. Je verwijst meteen naar een bron in de eerste zin die erop gebaseerd is, dus niet pas op het einde van een paragraaf.
\section{Machine Learning}

Machine Learning (ML) is een onderliggend deel van Artificial Intelligence (AI), een snel groeiend vakgebied op het raakvlak van data en statistiek dat feitgebaseerde beslissingen in verschillende sectoren aanstuurt \autocite{Jordan2015}. Middels het toepassen van wiskundige principes kan Machine Learning verbanden leggen tussen gegevens om betrouwbare voorspellingen te genereren. Dit wordt mogelijk gemaakt door het gebruik van Machine Learning algoritmen, waarmee computers kunnen leren van data. Met gebruik van iteratieve testen en validatie kunnen ze hun prestaties in de loop van de tijd verbeteren, waardoor ze nieuwe taken kunnen uitvoeren met nieuwe data \autocite{Shaveta2023}.

\section{Machine Learning Levenscyclus}

De levenscyclus van een typisch machine learning-project omvat verschillende fasen:

\subsection{Data Verzameling en Preprocessing}
In deze fase worden relevante gegevens verzameld en voorbereid voor analyse. Dit omvat het reinigen van gegevens, het oplossen van ontbrekende waarden en het transformeren van gegevens naar een geschikt formaat voor machine learning-modellen.

\subsection{Model Selectie en Training}
Hier wordt een geschikt machine learning-model geselecteerd op basis van de aard van de gegevens en het doel van het project. Het model wordt vervolgens getraind met behulp van de verzamelde gegevens, waarbij parameters worden aangepast om een optimaal voorspellingsresultaat te bereiken.

\subsection{Validatie en Evaluatie}
Na het trainen van het model wordt het gevalideerd met behulp van een aparte dataset die niet is gebruikt tijdens de training. Dit stelt vast hoe goed het model presteert op nieuwe, niet eerder geziene gegevens.

\subsection{Implementatie en Inzet}
Als het model succesvol is gevalideerd, wordt het geïmplementeerd in de productieomgeving om voorspellingen te genereren op nieuwe gegevens. Dit kan bijvoorbeeld inhouden dat het model wordt geïntegreerd in een bestaande softwareapplicatie of gegevensstroom.

\subsection{Monitoring en Onderhoud}
Nadat het model is ingezet, wordt het continu gemonitord om te controleren op prestatieverlies of achteruitgang in voorspellingsnauwkeurigheid. Indien nodig wordt het model opnieuw getraind met verse gegevens om de prestaties te behouden.

\section{Soorten Machine Learning Methoden}

Er zijn verschillende soorten machine learning-methoden, waaronder:

\subsection{Supervised Learning}
In deze methode wordt het model getraind op een dataset die gelabelde voorbeelden bevat, waarbij het doel is om een voorspellend model te ontwikkelen dat correcte uitvoer kan genereren voor nieuwe, niet eerder geziene gegevens.

\subsection{Unsupervised Learning}
Hierbij wordt het model getraind op een dataset zonder gelabelde voorbeelden. Het doel is om patronen en structuren in de gegevens te ontdekken zonder voorafgaande kennis van de uitvoer.

\subsection{Semi-supervised Learning}
Deze methode maakt gebruik van een combinatie van gelabelde en ongelabelde gegevens voor training. Het model profiteert van zowel de begeleide als de onbegeleide informatie om nauwkeuriger voorspellingen te maken.

\subsection{Reinforcement Learning}
Bij reinforcement learning leert het model door interactie met een dynamische omgeving, waarbij het beloningen ontvangt of straffen krijgt op basis van de acties die het uitvoert. Het doel is om een optimale strategie te ontwikkelen om de ontvangen beloningen te maximaliseren.

\subsection{Deep Learning}
Deep learning is een subset van machine learning die gebruikmaakt van kunstmatige neurale netwerken met meerdere lagen van verwerkingseenheden om complexe patronen in grote datasets te leren en te begrijpen.

\section{Conclusie}

Machine learning speelt een cruciale rol in het genereren van inzichten uit gegevens en het maken van voorspellingen op basis van complexe patronen. Door de levenscyclus van machine learning-projecten te begrijpen en verschillende soorten machine learning-methoden te verkennen, kunnen onderzoekers en ontwikkelaars effectievere en nauwkeurigere modellen ontwikkelen om een breed scala aan problemen op te lossen.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CI/CD pipelines}

Een Continuous Integration/Continuous Deployment (CI/CD) pipeline is een cruciaal onderdeel van moderne softwareontwikkeling. Het versnelt en verbetert de betrouwbaarheid van de levering van webapplicaties. De voordelen van CI/CD pipelines zijn onder andere:

\begin{enumerate}[label=\arabic*.]
    \item Versnelde softwareontwikkeling: Door automatisering van tests en deployments kunnen softwareteams sneller nieuwe features en bugfixes leveren.
    \item Betere kwaliteit: Continue integratie en testing helpen om bugs vroegtijdig te detecteren en te corrigeren.
    \item Verhoogde betrouwbaarheid: Continue deployment zorgt voor een consistente en betrouwbare implementatie van software in de productieomgeving.
    \item Verbeterde samenwerking: CI/CD pipelines bevorderen de samenwerking tussen softwareontwikkelaars, testers en operationele teams.
\end{enumerate}

\section{De werking van CI/CD pipelines}

Een CI/CD pipeline bestaat uit een reeks geordende stappen die codewijzigingen automatisch integreren, testen en implementeren. De stappen in een pipeline kunnen worden gecategoriseerd als:

\begin{enumerate}[label=\arabic*.]
    \item Continue integratie: Codewijzigingen van verschillende developers worden samengevoegd en getest.
    \item Continue testing: Geautomatiseerde tests controleren de functionaliteit en kwaliteit van de code.
    \item Continue delivery: De geteste code wordt klaargemaakt voor implementatie in de productieomgeving.
    \item Continuous deployment: De geprepareerde code wordt automatisch gedeployed in de productieomgeving.
\end{enumerate}

\section{CI/CD pipelines in het kader van datamanagement}

Binnen het domein van datamanagement benadrukken Samad (2018) en Vadavalasa (2020) de cruciale aspecten van het optimaliseren van beperkte datasets en de implementatie van Continuous Integration in de datapipeline.

\begin{itemize}
    \item Optimaliseren van beperkte datasets: Samad (2018) belicht de noodzaak om data-efficiënte ML-modellen te ontwikkelen, gezien de hoge kosten en tijdsbesteding die gepaard gaan met dataverzameling.
    \item Implementatie van Continuous Integration in de datapipeline: Vadavalasa (2020) benadrukt het belang van het integreren van CI/CD praktijken in datapipelines om de consistentie en betrouwbaarheid van datastromen te garanderen.
\end{itemize}

\section{De rol van datapipelines in machine learning}

Zhang (2022) richt zich op het ontwerpen en automatiseren van datapipelines. Hij toont aan dat datapipelines de efficiëntie van ML-modeltraining aanzienlijk kunnen verhogen door:

\begin{itemize}
    \item Dataverwerking: Datapipelines zorgen voor het opschonen, transformeren en normaliseren van data, waardoor onnodige of ontbrekende data de modelnauwkeurigheid niet beïnvloedt.
    \item Automatisering: Datapipelines automatiseren repetitieve taken in de ML-workflow, waardoor de doorlooptijd van modelontwikkeling wordt verkort.
\end{itemize}

\section{Conclusie}

CI/CD pipelines zijn een essentieel onderdeel van moderne softwareontwikkeling. Ze versnellen de levering van software, verhogen de kwaliteit en betrouwbaarheid, en bevorderen de samenwerking tussen teams. In het kader van datamanagement helpen CI/CD pipelines om data-efficiënte ML-modellen te ontwikkelen en de consistentie en betrouwbaarheid van datastromen te garanderen. Datapipelines spelen een cruciale rol in ML door dataverwerking te automatiseren en de efficiëntie van modeltraining te verhogen.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Machine Learning Pipelines}

Machine learning (ML) is een krachtige technologie die in diverse sectoren wordt toegepast om waardevolle inzichten te verwerven uit data. De ontwikkeling van ML-modellen omvat echter een complexe reeks stappen, van dataverzameling tot modeltraining en -implementatie. Dit proces is vaak repetitief en tijdrovend, wat de efficiëntie en schaalbaarheid van ML-projecten belemmert. Hierdoor worden pipelines gebruikt die het process automatisch laat lopen.

\section{De levenscyclus van machine learning}

De levenscyclus van ML omvat de volgende stappen:
\begin{enumerate}[label=\arabic*.]
    \item Dataverzameling en -voorbereiding: Het verzamelen en opschonen van relevante data, inclusief het transformeren en normaliseren van de data.
    \item Feature engineering: Het selecteren en creëren van features die relevant zijn voor de ML-taak.
    \item Modeltraining: Het trainen van een ML-model op basis van de voorbereide data.
    \item Modelkeuze: Het selecteren van het beste model op basis van prestatie-evaluatie.
    \item Modelfinetuning: Het optimaliseren van de hyperparameters van het geselecteerde model.
    \item Modelvalidatie: Het evalueren van de prestaties van het model op onafhankelijke data.
    \item Modeldeployement: Het implementeren van het model in een productieomgeving.
    \item Modelbewaking: Het monitoren van de prestaties van het model in de productieomgeving en het uitvoeren van hertraining indien nodig.
\end{enumerate}

\section{Verbeteringen door machine learning pipelines}

Machine learning pipelines automatiseren en stroomlijnen de stappen in de levenscyclus van ML. De voordelen van pipelines zijn onder andere:
\begin{itemize}
    \item Verhoogde efficiëntie: Pipelines automatiseren repetitieve taken, waardoor de doorlooptijd van ML-projecten wordt verkort.
    \item Verbeterde reproduceerbaarheid: Pipelines garanderen dat experimenten op een consistente manier worden uitgevoerd, waardoor de reproduceerbaarheid van de resultaten wordt gewaarborgd.
    \item Betere schaalbaarheid: Pipelines vergemakkelijken de implementatie van ML-modellen op grotere datasets en in productieomgevingen.
    \item Verhoogde transparantie: Pipelines documenteren de stappen in de ML-workflow, waardoor de transparantie en het begrip van het proces worden vergroot.
\end{itemize}

\section{Hoe machine learning pipelines werken}

Pipelines bestaan uit een reeks geordende stappen die data transformeren en modellen trainen. De stappen in een pipeline kunnen worden gecategoriseerd als:
\begin{enumerate}[label=\arabic*.]
    \item Data-ingestion: Het laden van data uit verschillende bronnen.
    \item Data-preprocessing: Het opschonen, transformeren en normaliseren van data.
    \item Feature engineering: Het selecteren en creëren van features.
    \item Modeltraining: Het trainen van een ML-model op basis van de voorbereide data.
    \item Modelbeoordeling: Het evalueren van de prestaties van het model.
    \item Modeldeployement: Het implementeren van het model in een productieomgeving.
\end{enumerate}
Pipelines kunnen worden geïmplementeerd met behulp van diverse tools en frameworks, zoals Apache Airflow, Kubeflow, TensorFlow Extended (TFX), en Amazon SageMaker.

\section{Conclusie}

Machine learning pipelines bieden een efficiënte en schaalbare manier om ML-modellen te ontwikkelen en te implementeren. Door de stappen in de levenscyclus van ML te automatiseren, bevorderen pipelines de reproduceerbaarheid, transparantie en efficiëntie van ML-projecten.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Kedro}

In het domein van onderzoek en ontwikkeling op het gebied van Machine Learning (ML) is effectief beheer en opslag van gegevens cruciaal. Kedro, een open-source Python library voor het bouwen van betrouwbare, reproduceerbare en onderhoudbare machine learning-pipelines, komt naar voren als een krachtig instrument voor onderzoekers bij het opzetten en beheren van lokaal uitgevoerde ML-pipelines. Deze scriptie onderzoekt de verdiensten van het gebruik van Kedro in lokale ML-omgevingen en benadrukt de voordelen ervan bij het stroomlijnen van MLOps-praktijken voor onderzoek en scriptieontwikkeling.

\section{Voordelen van Lokale Implementatie van Kedro voor ML Pipelines}

\subsection{Flexibele en Modulaire Pipelines}
Kedro maakt het mogelijk om machine learning-pipelines op een flexibele en modulaire manier te bouwen, waardoor onderzoekers gemakkelijk verschillende componenten kunnen toevoegen, verwijderen of aanpassen. Dit verbetert de aanpasbaarheid van de pipeline aan veranderende onderzoeksbehoeften.

\subsection{Versiebeheer en Reproduceerbaarheid}
Met Kedro kunnen onderzoekers versiebeheer integreren in hun ML-pipelines, waardoor ze experimenten kunnen reproduceren en resultaten kunnen valideren. Dit is essentieel voor het bevorderen van transparantie en betrouwbaarheid in onderzoek.

\subsection{Geïntegreerde Gegevenscatalogus}
Kedro biedt een geïntegreerde gegevenscatalogus waarmee onderzoekers gemakkelijk datasets kunnen beheren, documenteren en traceren binnen de ML-pipeline. Dit vereenvoudigt het gegevensbeheer en bevordert de samenwerking tussen teamleden.

\subsection{Ondersteuning voor Lokale Uitvoering}
Kedro ondersteunt lokale uitvoering van ML-pipelines, waardoor onderzoekers offline experimenten kunnen uitvoeren en ontwikkelen. Dit is met name gunstig voor onderzoek dat gevoelige gegevens omvat of waar cloudresources niet beschikbaar zijn.

\section{Integratie met Lokale ML Tools en Frameworks}

\subsection{Compatibiliteit met Populaire ML-frameworks}
Kedro integreert naadloos met populaire ML-frameworks zoals TensorFlow, PyTorch en scikit-learn, waardoor onderzoekers hun favoriete tools kunnen blijven gebruiken binnen de Kedro-pipeline. Dit minimaliseert de leercurve en bevordert een consistente ontwikkelingservaring.

\subsection{Gebruik van Virtual Environments}
Kedro ondersteunt het gebruik van virtual environments, waardoor onderzoekers afhankelijkheden kunnen isoleren en een gecontroleerde ontwikkelingsomgeving kunnen behouden. Dit helpt bij het voorkomen van conflicten tussen verschillende projecten en zorgt voor reproduceerbare resultaten.

\section{Geavanceerde Functionaliteiten}

\subsection{Automatische Documentatie}
Kedro genereert automatisch gedetailleerde documentatie voor ML-pipelines, inclusief informatie over datasets, parameters en dependencies. Dit verbetert de traceerbaarheid en maakt het gemakkelijker om de pipeline te begrijpen en te onderhouden.

\subsection{Pipelinevisualisatie}
Kedro biedt tools voor het visualiseren van ML-pipelines, waardoor onderzoekers een overzicht krijgen van de gegevensstroom en de interacties tussen verschillende componenten. Dit vergemakkelijkt het begrip van de pipeline-architectuur en identificeert mogelijke optimalisaties.

\section{Conclusie}

Kedro biedt een overtuigende oplossing voor onderzoekers bij het opzetten en beheren van machine learning-pipelines in lokale omgevingen. De flexibiliteit, ondersteuning voor versiebeheer, geïntegreerde gegevenscatalogus en compatibiliteit met populaire ML-frameworks maken het tot een waardevol instrument voor onderzoeksinspanningen. Door gebruik te maken van Kedro kunnen onderzoekers hun ontwikkelingsworkflows stroomlijnen, experimenten reproduceerbaar maken en zich richten op het verkennen van complexe onderzoeksvraagstukken.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{MLFlow}

\textcite{MLflow2023} benadrukt gebruiksgemak en aanpasbaarheid. Het biedt een gestandaardiseerde manier om Machine Learning projecten te beheren, ongeacht de programmeertaal die wordt gebruikt. Met MLflow kunnen experimenten worden bijgehouden, modelparameters worden geregistreerd, modellen worden beheerd en zelfs modellen worden geïmplementeerd in verschillende omgevingen.

\section{MLflow: Een Overzicht}

MLflow is een open-source Python-bibliotheek ontwikkeld door Databricks, die een brede functionaliteit biedt voor het beheren van Machine Learning (ML) projecten. De belangrijkste pijlers van MLflow zijn Tracking, Projects, Models en Registry.

\subsection{Tracking}
Tracking biedt een eenvoudige manier om experimenten te volgen en resultaten te vergelijken. MLflow houdt nauwgezet relevante details bij gedurende de ML-levenscyclus, zoals code, parameters, metrieken en artefacten (modellen, datasets), waardoor onderzoekers naadloos eerdere experimenten kunnen reproduceren en verschillende configuraties kunnen vergelijken.

\subsection{Projects}
Projects zorgen voor een uniforme structuur voor Machine Learning projecten en bevorderen de herbruikbaarheid. Onderzoekers kunnen gestandaardiseerde projectstructuren definiëren met MLflow Projects, waardoor consistente en reproduceerbare onderzoeksomgevingen worden bevorderd.

\subsection{Models}
Models biedt tools om modellen in te pakken en te implementeren in verschillende omgevingen. MLflow stroomlijnt de implementatie van ML-modellen in productieomgevingen door ze te verpakken in een gestandaardiseerd formaat, inclusief de modelcode, afhankelijkheden en configuratiedetails.

\subsection{Registry}
Registry fungeert als een centrale hub voor het beheren van modelversies. MLflow stelt onderzoekers in staat om een gecentraliseerd repository in te stellen voor geregistreerde modellen, waardoor ze verschillende versies van modellen kunnen organiseren, volgen en openen.

\section{Voordelen van MLflow}

MLflow biedt verschillende voordelen voor onderzoekers in het beheer van Machine Learning projecten:

\begin{itemize}
    \item Verbeterde Reproduceerbaarheid: MLflow's zorgvuldige logging en trackingmogelijkheden zorgen ervoor dat experimenten gemakkelijk reproduceerbaar zijn, wat de geloofwaardigheid en betrouwbaarheid van onderzoek versterkt.
    \item Gestroomlijnde Samenwerking: Gecentraliseerd model- en experimentbeheer bevordert naadloze samenwerking tussen onderzoekers, omdat ze elkaars werk gemakkelijk kunnen delen en volgen.
    \item Verbeterde Efficiëntie: MLflow automatiseert tijdrovende taken zoals experimenttracking en modelbeheer, waardoor onderzoekers waardevolle tijd kunnen vrijmaken voor kernonderzoeksactiviteiten.
    \item Vereenvoudigde Implementatie: MLflow stroomlijnt het implementatieproces, waardoor onderzoekers hun modellen snel en efficiënt kunnen overbrengen van onderzoek naar productieomgevingen.
\end{itemize}

\section{Conclusie}

In conclusie, MLflow vestigt zich als een onschatbare troef voor onderzoekers die zich bezighouden met Machine Learning-projecten. Door reproduceerbaarheid te bevorderen, samenwerking te verbeteren en experimentatie, implementatie en beheer te stroomlijnen, stelt MLflow onderzoekers in staat om de kwaliteit en efficiëntie van hun onderzoeksinspanningen te verbeteren.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Kubeflow}

In het domein van onderzoek en ontwikkeling op het gebied van Machine Learning (ML) is effectief beheer en opschaling van machine learning-workloads cruciaal. Kubeflow, een open-source machine learning toolkit ontworpen voor Kubernetes, biedt een krachtige infrastructuur voor onderzoekers bij het opzetten en beheren van machine learning-pipelines in zowel lokale als cloudomgevingen. Deze scriptie onderzoekt de verdiensten van het gebruik van Kubeflow in lokale ML-omgevingen en benadrukt de voordelen ervan bij het stroomlijnen van MLOps-praktijken voor onderzoek en scriptieontwikkeling.

\section{Voordelen van Lokale Implementatie van Kubeflow voor ML Pipelines}

\subsection{Schaalbaarheid en Flexibiliteit}
Kubeflow maakt gebruik van Kubernetes om machine learning-workloads te beheren, waardoor onderzoekers de mogelijkheid hebben om hun ML-pipelines eenvoudig op te schalen of af te schalen afhankelijk van de behoeften van het onderzoek. Dit maakt het een geschikte keuze voor onderzoeksgroepen van verschillende groottes.

\subsection{Geautomatiseerd Beheer}
Met Kubeflow kunnen onderzoekers de implementatie en het beheer van machine learning-pipelines automatiseren, waardoor ze minder tijd hoeven te besteden aan het handmatig configureren en monitoren van infrastructuur. Dit verhoogt de operationele efficiëntie en stelt onderzoekers in staat zich te concentreren op het onderzoek zelf.

\subsection{Reproduceerbare Experimenten}
Kubeflow biedt tools en functies voor het vastleggen van de omgeving en het versiebeheer van de code, waardoor onderzoekers experimenten kunnen reproduceren en resultaten kunnen valideren. Dit draagt bij aan de transparantie en betrouwbaarheid van het onderzoek.

\subsection{Ondersteuning voor Diverse Workloads}
Kubeflow ondersteunt een breed scala aan machine learning-workloads, waaronder training, inferentie en hyperparameteroptimalisatie, waardoor onderzoekers flexibel kunnen experimenteren met verschillende modellen en technieken binnen dezelfde infrastructuur.

\section{Integratie met Lokale ML Tools en Frameworks}

\subsection{Naadloze Integratie met Kubernetes}
Kubeflow is ontworpen om naadloos te integreren met Kubernetes, waardoor onderzoekers het gemakkelijk kunnen implementeren en beheren op lokale Kubernetes-clusters. Dit minimaliseert de operationele overhead en bevordert een consistente ontwikkelingservaring.

\subsection{Compatibiliteit met ML Frameworks}
Kubeflow biedt integratie met populaire ML-frameworks zoals TensorFlow, PyTorch en scikit-learn, waardoor onderzoekers hun favoriete tools kunnen blijven gebruiken binnen de Kubeflow-pipelines. Dit maximaliseert de flexibiliteit en maakt het gemakkelijk om bestaande modellen en code te hergebruiken.

\section{Geavanceerde Functionaliteiten}

\subsection{Experiment Tracking en Monitoring}
Kubeflow biedt functionaliteiten voor het bijhouden en monitoren van machine learning-experimenten, waardoor onderzoekers inzicht krijgen in de voortgang van hun onderzoek en potentiële problemen kunnen identificeren. Dit vergemakkelijkt het optimaliseren van de prestaties en het vinden van de beste modellen.

\subsection{Model Deployment en Serving}
Kubeflow ondersteunt model deployment en serving, waardoor onderzoekers getrainde modellen gemakkelijk kunnen implementeren en schalen voor productiegebruik. Dit vergemakkelijkt de overgang van experimentele prototypen naar operationele systemen.

\section{Conclusie}

Kubeflow biedt een overtuigende oplossing voor onderzoekers bij het opzetten en beheren van machine learning-pipelines in lokale omgevingen. De schaalbaarheid, geautomatiseerd beheer, ondersteuning voor reproduceerbare experimenten en integratie met populaire ML-frameworks maken het tot een waardevol instrument voor onderzoeksinspanningen. Door gebruik te maken van Kubeflow kunnen onderzoekers hun ontwikkelingsworkflows stroomlijnen, experimenten efficiënter uitvoeren en zich richten op het verkennen van complexe onderzoeksvraagstukken.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Minio}

In het domein van onderzoek en ontwikkeling op het gebied van Machine Learning (ML) is effectief beheer en opslag van gegevens cruciaal. Minio, een open-source, high-performance objectopslagoplossing, komt naar voren als een krachtig instrument voor onderzoekers bij het opzetten en beheren van lokaal uitgevoerde ML-pipelines. Deze scriptie onderzoekt de verdiensten van het gebruik van Minio in lokale ML-omgevingen en benadrukt de voordelen ervan bij het stroomlijnen van MLOps-praktijken voor onderzoek en scriptieontwikkeling.

\section{Voordelen van Lokale Implementatie van Minio voor ML Pipelines}

\subsection{Kosteneffectieve Opslag}
Minio elimineert licentiekosten die gepaard gaan met eigen oplossingen, waardoor het een budgetvriendelijke optie is voor onderzoeksprojecten. Dit is met name gunstig voor kleinere onderzoeksgroepen of individuen met beperkte middelen.

\subsection{Vereenvoudigd Gegevensbeheer}
Minio's op objecten gebaseerde opslag vereenvoudigt het gegevensbeheer voor ML-pipelines. Elk gegevenspunt wordt opgeslagen als een onveranderlijk object met een unieke identifier, waardoor directe toegang en versiebeheer mogelijk zijn. Dit vereenvoudigt de gegevensopvraging en de reproduceerbaarheid van experimenten, cruciale aspecten van onderzoek.

\subsection{Schaalbaarheid en Flexibiliteit}
De horizontale schaalbaarheid van Minio stelt onderzoekers in staat om de opslagcapaciteit geleidelijk te vergroten naarmate hun datavolume groeit. Deze aanpasbaarheid zorgt ervoor dat de opslagoplossing kan voldoen aan de evoluerende behoeften van onderzoeksprojecten.

\subsection{Offline Experimenten}
Minio stelt onderzoekers in staat om ML-pipelines uit te voeren en gegevens volledig lokaal op te slaan, waardoor offline experimenten en ontwikkeling mogelijk zijn. Dit is met name voordelig voor onderzoek met gevoelige gegevens die niet op cloudplatforms kunnen worden opgeslagen vanwege privacy- of beveiligingsproblemen.

\section{Integratie met Lokale ML Tools en Frameworks}

\subsection{Docker en Kubernetes}
Minio kan eenvoudig worden gecontaineriseerd met behulp van Docker en worden ingezet op lokale Kubernetes-clusters, waardoor onderzoekers het naadloos kunnen integreren in hun bestaande lokale ontwikkelings- en implementatieomgeving. Dit vergemakkelijkt een consistente workflow voor zowel lokale ontwikkeling als mogelijke toekomstige cloudimplementatie.

\subsection{ML Frameworks}
Minio integreert met populaire ML-frameworks zoals TensorFlow en PyTorch via hun objectopslag-API's, waardoor onderzoekers direct toegang hebben tot en gegevens kunnen verwerken die zijn opgeslagen in Minio met behulp van vertrouwde tools. Dit vereenvoudigt het gegevensbeheer binnen de ML-pipeline.

\section{Geavanceerde Functionaliteiten}

\subsection{Beveiligingsfuncties}
Minio biedt verschillende beveiligingsfuncties, waaronder gebruikersauthenticatie, toegangscontrole en versleuteling, waardoor de vertrouwelijkheid en integriteit van onderzoeksgegevens zelfs in een lokale omgeving worden gewaarborgd. Het implementeren van passende beveiligingsmaatregelen is cruciaal voor het beschermen van gevoelige onderzoeksgegevens.

\subsection{Gegevenslevenscyclusbeheer}
Minio stelt onderzoekers in staat om beleidsregels voor gegevenslevenscyclus te definiëren, zoals het automatisch archiveren van oudere gegevens of het verwijderen van tijdelijke bestanden. Dit helpt bij het handhaven van een efficiënt gebruik van opslagruimte en voorkomt gegevensrommel binnen de lokale omgeving.

\subsection{Monitoring en Observatie}
Minio biedt monitoringtools en API's om opslaggebruik bij te houden, potentiële problemen te identificeren en inzicht te krijgen in gegevenstoegangspatronen. Deze informatie kan waardevol zijn voor het optimaliseren van de lokale opslagconfiguratie en het zorgen voor een soepele werking van ML-pipelines.

\section{Conclusie}

Minio biedt een overtuigende oplossing voor onderzoekers bij het opzetten en beheren van gegevensopslag voor lokaal uitgevoerde ML-pipelines. De kosteneffectiviteit, het gemak van beheer, de schaalbaarheid en de offline mogelijkheden maken het tot een waardevol instrument voor onderzoeksinspanningen, waardoor efficiënte MLOps-praktijken worden bevorderd en reproduceerbaar onderzoek wordt vergemakkelijkt. Door gebruik te maken van Minio kunnen onderzoekers hun lokale ontwikkelingsworkflows stroomlijnen en zich richten op kernonderzoeksactiviteiten.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Apache Beam}

De exponentiële groei van gegevens in diverse formaten stelt organisaties voor aanzienlijke uitdagingen bij het extraheren van zinvolle inzichten {BRON}. Apache Beam heeft zich ontwikkeld tot een overtuigende oplossing, met een uniform programmeringsmodel dat ontwikkelaars in staat stelt schaalbare, fouttolerante gegevensverwerkingspipelines te construeren die zowel batch- als real-time streaminggegevens kunnen verwerken. Deze scriptie onderzoekt de verdiensten van Apache Beam, met name de geschiktheid ervan voor verschillende toepassingen voor het verwerken van big data, waarbij de voordelen ervan worden benadrukt in de context van onderzoek en scriptieontwikkeling.

\section{Uniform Programmeringsmodel}

De kernkracht van Apache Beam ligt in zijn abstractie van onderliggende infrastructuur, waardoor ontwikkelaars zich kunnen concentreren op logische gegevenstransformaties in plaats van te worden gehinderd door implementatiedetails op laag niveau. Deze abstractielaag presenteert een draagbaar programmeringsmodel, waardoor ontwikkelaars code kunnen schrijven die onafhankelijk is van de bron en uitvoerder. In eenvoudiger bewoordingen:
\begin{itemize}
    \item Source-agnostic: Code blijft onafhankelijk van de gegevensbron (bijv. databases, berichtenwachtrijen, bestanden), waardoor gemakkelijk kan worden geschakeld tussen verschillende gegevensbronnen zonder significante codeaanpassingen.
    \item Runner-agnostic: Code blijft onafhankelijk van het onderliggende uitvoeringsplatform (bijv. Apache Flink, Apache Spark, Google Cloud Dataflow), waardoor dezelfde pipelinecode naadloos op verschillende platforms kan worden uitgevoerd.
\end{itemize}

\section{Belangrijkste Functionaliteiten}

\subsection{Gegevenstransformaties}
Beam's kernkracht ligt in zijn rijke set van primitieve transformaties (bijv. filtering, mapping, aggregatie) die aan elkaar kunnen worden gekoppeld om complexe gegevensverwerkingspipelines te vormen.

\subsection{Windowing}
Beam vergemakkelijkt de verwerking van gegevensstromen door ze in eindige vensters te verdelen, waardoor ontwikkelaars gegevens in stukken in de tijd kunnen analyseren. Dit is cruciaal voor real-time toepassingen waarbij het continu analyseren van de volledige stroom niet haalbaar is.

\subsection{State Management}
Beam ondersteunt het beheren van staat (bijv. bijhouden van tussentijdse resultaten) over verschillende verwerkingsunits, waardoor complexe berekeningen mogelijk zijn waarbij historische informatie wordt bijgehouden.

\subsection{Fouttolerantie}
Beam-pipelines zijn inherent fouttolerant en behandelen automatisch storingen en herstellen daarvan zonder gegevensverlies. Dit zorgt voor betrouwbare verwerking, zelfs bij systeemproblemen.

\section{Voordelen}

\subsection{Stream Processing}
Beam is bijzonder geschikt voor onderzoeksgebieden die te maken hebben met real-time gegevensstromen. Bijvoorbeeld, onderzoekers kunnen Beam gebruiken om sensorgegevens van experimenten te analyseren, financiële transacties in realtime te verwerken, of socialemediastromen te analyseren om realtime trends te bestuderen.

\subsection{Schaalbaarheid}
Beam-pipelines kunnen horizontaal worden geschaald door meer verwerkingswerkers toe te voegen, waardoor onderzoekers efficiënt met grootschalige gegevens kunnen omgaan. Deze aanpasbaarheid is cruciaal voor het omgaan met het groeiende volume aan gegevens in veel onderzoeksprojecten.

\subsection{Flexibiliteit}
De bron-onafhankelijke aard van Beam stelt onderzoekers in staat om gemakkelijk te schakelen tussen verschillende gegevensbronnen zonder belangrijke codeaanpassingen, waardoor experimenten met diverse datasets worden gestimuleerd.

\subsection{Reproduceerbaarheid}
Het draagbare programmeringsmodel van Beam bevordert de reproduceerbaarheid, aangezien code gemakkelijk kan worden gedeeld en uitgevoerd op verschillende platforms, waardoor samenwerking en verificatie van onderzoeksresultaten worden vergemakkelijkt.

\section{Integratie met Bestaande Systemen}

Beam integreert naadloos met verschillende populaire big data-platforms en -tools:

\subsection{Cloudplatforms}
Beam-pipelines kunnen worden uitgevoerd op toonaangevende cloudplatforms zoals Google Cloud Platform (GCP), Amazon Web Services (AWS) en Microsoft Azure, waarbij gebruik wordt gemaakt van de kracht van cloudresources voor efficiënte en schaalbare gegevensverwerking.

\subsection{Opslagsystemen}
Beam-pipelines kunnen eenvoudig gegevens lezen van en schrijven naar populaire opslagsystemen zoals Apache HDFS, Amazon S3 en Google Cloud Storage, waardoor flexibiliteit in gegevenstoegang en -beheer wordt geboden.

\subsection{Machine Learning Frameworks}
Integratie met frameworks zoals TensorFlow, PyTorch en scikit-learn stelt onderzoekers in staat om machine learning-modellen naadloos op te nemen in hun gegevensverwerkingspipelines, waardoor taken zoals realtime anomaliedetectie, sentimentanalyse of voorspellende modellering op streaminggegevens mogelijk worden.

\section{Verder dan de Basis}

\subsection{Apache Beam SQL}
Beam biedt een SQL-achtige interface voor het schrijven van gegevensverwerkingspipelines, als alternatief voor gebruikers die bekend zijn met SQL-syntax.

\subsection{User-Defined Functions (UDFs)}
Beam stelt ontwikkelaars in staat om hun eigen aangepaste functies (UDFs) te definiëren in Python, Java of Go, waardoor de implementatie van specifieke verwerkingslogica op maat van onderzoeksproblemen mogelijk is.

\subsection{Testen en Debuggen}
Beam biedt verschillende tools en frameworks voor het testen en debuggen van pipelines, waardoor de juistheid en robuustheid van onderzoeksresultaten worden gegarandeerd.

\section{Conclusie}

Apache Beam biedt een overtuigend programmeermodel voor het construeren van robuuste, schaalbare en fouttolerante gegevensverwerkingspipelines die zowel batch- als real-time streaminggegevens kunnen verwerken. Zijn bron- en uitvoerder-agnostische aard, gekoppeld aan zijn rijke set functies en naadloze integratie met populaire big data-tools, maken het tot een onschatbaar hulpmiddel voor onderzoekers die werken met grootschalige gegevens in verschillende domeinen. Door Beam te benutten, kunnen onderzoekers zich concentreren op de kernlogica van hun onderzoek terwijl ze profiteren van de abstractie- en uitvoeringsmogelijkheden van het platform.

