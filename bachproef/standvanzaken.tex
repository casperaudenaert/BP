\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

%Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

%Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz.\ naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin (narratieve referentie), gebruik je \texttt{$\backslash${}textcite\{\}}. Soms is de auteursnaam niet expliciet een onderdeel van de zin, dan gebruik je \texttt{$\backslash${}autocite\{\}} (referentie tussen haakjes). Dit gebruik je bv.~bij een citaat, of om in het bijschrift van een overgenomen afbeelding, broncode, tabel, enz. te verwijzen naar de bron. In de volgende paragraaf een voorbeeld van elk.

%\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

%Let er ook op: het \texttt{cite}-commando voor de punt, dus binnen de zin. Je verwijst meteen naar een bron in de eerste zin die erop gebaseerd is, dus niet pas op het einde van een paragraaf.
\section{Machine Learning}

Machine Learning (ML) is een onderliggend deel van Artificial Intelligence (AI), een snel groeiend vakgebied op het raakvlak van data en statistiek dat feitgebaseerde beslissingen in verschillende sectoren aanstuurt \autocite{Jordan2015}. Middels het toepassen van wiskundige principes kan Machine Learning verbanden leggen tussen gegevens om betrouwbare voorspellingen te genereren. Dit wordt mogelijk gemaakt door het gebruik van Machine Learning algoritmen, waarmee computers kunnen leren van data. Met gebruik van iteratieve testen en validatie kunnen ze hun prestaties in de loop van de tijd verbeteren, waardoor ze nieuwe taken kunnen uitvoeren met nieuwe data \autocite{Shaveta2023}.

\subsection{Machine Learning Levenscyclus}

De levenscyclus van een typisch machine learning-project omvat verschillende fasen:

\begin{itemize}
    \item \textbf{Data Verzameling en Preprocessing:} In deze fase worden relevante gegevens verzameld en voorbereid voor analyse. Dit omvat het reinigen van gegevens, het oplossen van ontbrekende waarden en het transformeren van gegevens naar een geschikt formaat voor machine learning-modellen\autocite{Schlegel2022}.
    \item \textbf{Model Selectie en Training:} Hier wordt een geschikt machine learning-model geselecteerd op basis van de aard van de gegevens en het doel van het project. Het model wordt vervolgens getraind met behulp van de verzamelde gegevens, waarbij parameters worden aangepast om een optimaal voorspellingsresultaat te bereiken\autocite{Schlegel2022}.
    \item \textbf{Validatie en Evaluatie:}  Na het trainen van het model wordt het gevalideerd met behulp van een aparte dataset die niet is gebruikt tijdens de training. Dit stelt vast hoe goed het model presteert op nieuwe, niet eerder geziene gegevens\autocite{Schlegel2022}.
    \item \textbf{Implementatie en Inzet:}  Als het model succesvol is gevalideerd, wordt het geïmplementeerd in de productieomgeving om voorspellingen te genereren op nieuwe gegevens. Dit kan bijvoorbeeld inhouden dat het model wordt geïntegreerd in een bestaande softwareapplicatie of gegevensstroom\autocite{Schlegel2022}.
    \item \textbf{Monitoring en Onderhoud:}  Nadat het model is ingezet, wordt het continu gemonitord om te controleren op prestatieverlies of achteruitgang in voorspellingsnauwkeurigheid. Indien nodig wordt het model opnieuw getraind met verse gegevens om de prestaties te behouden\autocite{Schlegel2022}.
  \end{itemize}

\subsection{Soorten Machine Learning Methoden}

Er zijn verschillende soorten machine learning-methoden, waaronder \autocite{Mahesh2019}:

\subsubsection{Supervised Learning}
In deze methode wordt het model getraind op een dataset die gelabelde voorbeelden bevat, waarbij het doel is om een voorspellend model te ontwikkelen dat correcte uitvoer kan genereren voor nieuwe, niet eerder geziene gegevens.

\subsubsection{Unsupervised Learning}
Hierbij wordt het model getraind op een dataset zonder gelabelde voorbeelden. Het doel is om patronen en structuren in de gegevens te ontdekken zonder voorafgaande kennis van de uitvoer.

\subsubsection{Semi-supervised Learning}
Deze methode maakt gebruik van een combinatie van gelabelde en ongelabelde gegevens voor training. Het model profiteert van zowel de begeleide als de onbegeleide informatie om nauwkeuriger voorspellingen te maken.

\subsubsection{Reinforcement Learning}
Bij reinforcement learning leert het model door interactie met een dynamische omgeving, waarbij het beloningen ontvangt of straffen krijgt op basis van de acties die het uitvoert. Het doel is om een optimale strategie te ontwikkelen om de ontvangen beloningen te maximaliseren\autocite{Mahesh2019}.

\subsubsection{Deep Learning}
Deep learning is een subset van machine learning die gebruikmaakt van kunstmatige neurale netwerken met meerdere lagen van verwerkingseenheden om complexe patronen in grote datasets te leren en te begrijpen.

Machine learning speelt een cruciale rol in het genereren van inzichten uit gegevens en het maken van voorspellingen op basis van complexe patronen. Door de levenscyclus van machine learning-projecten te begrijpen en verschillende soorten machine learning-methoden te verkennen, kunnen onderzoekers en ontwikkelaars effectievere en nauwkeurigere modellen ontwikkelen om een breed scala aan problemen op te lossen.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CI/CD pipelines}

Een Continuous Integration/Continuous Deployment (CI/CD) pipeline is een cruciaal onderdeel van moderne softwareontwikkeling. Het versnelt en verbetert de betrouwbaarheid van de levering van webapplicaties. De voordelen van CI/CD pipelines zijn onder andere:

\begin{enumerate}[label=\arabic*.]
    \item Versnelde softwareontwikkeling: Door automatisering van tests en deployments kunnen softwareteams sneller nieuwe features en bugfixes leveren.
    \item Betere kwaliteit: Continue integratie en testing helpen om bugs vroegtijdig te detecteren en te corrigeren.
    \item Verhoogde betrouwbaarheid: Continue deployment zorgt voor een consistente en betrouwbare implementatie van software in de productieomgeving.
    \item Verbeterde samenwerking: CI/CD pipelines bevorderen de samenwerking tussen softwareontwikkelaars, testers en operationele teams.
\end{enumerate}

Een CI/CD pipeline bestaat uit een geordende reeks stappen die codewijzigingen automatisch integreren, testen en implementeren. De stappen in een dergelijke pipeline kunnen worden opgedeeld in verschillende categorieën.

Continue integratie omvat het samenvoegen en testen van codewijzigingen van diverse ontwikkelaars. Dit proces verzekert dat de verschillende delen van de code goed samenwerken en geen conflicten veroorzaken.

Continue testing is het volgende stadium, waar geautomatiseerde tests worden uitgevoerd om de functionaliteit en kwaliteit van de code te controleren. Dit zorgt ervoor dat eventuele fouten of bugs worden opgespoord voordat de code verder wordt verwerkt.

Vervolgens komt continue delivery, waar de geteste code wordt voorbereid voor implementatie in de productieomgeving. Dit omvat vaak het verpakken van de code en het gereedmaken van eventuele configuratiebestanden.

Tenslotte is er continuous deployment, waar de voorbereide code automatisch wordt gedeployed in de productieomgeving. Dit proces minimaliseert handmatige tussenkomst en verzekert een snelle en consistente implementatie van nieuwe code.

\subsection{CI/CD pipelines in het kader van datamanagement}

Binnen het domein van datamanagement benadrukken Samad (2018) en Vadavalasa (2020) de cruciale aspecten van het optimaliseren van beperkte datasets en de implementatie van Continuous Integration in de datapipeline.

\begin{itemize}
    \item Optimaliseren van beperkte datasets: Samad (2018) belicht de noodzaak om data-efficiënte ML-modellen te ontwikkelen, gezien de hoge kosten en tijdsbesteding die gepaard gaan met dataverzameling.
    \item Implementatie van Continuous Integration in de datapipeline: Vadavalasa (2020) benadrukt het belang van het integreren van CI/CD praktijken in datapipelines om de consistentie en betrouwbaarheid van datastromen te garanderen.
\end{itemize}

\subsection{De rol van datapipelines in machine learning}

Zhang (2022) richt zich op het ontwerpen en automatiseren van datapipelines. Hij toont aan dat datapipelines de efficiëntie van ML-modeltraining aanzienlijk kunnen verhogen door:

\begin{itemize}
    \item Dataverwerking: Datapipelines zorgen voor het opschonen, transformeren en normaliseren van data, waardoor onnodige of ontbrekende data de modelnauwkeurigheid niet beïnvloedt.
    \item Automatisering: Datapipelines automatiseren repetitieve taken in de ML-workflow, waardoor de doorlooptijd van modelontwikkeling wordt verkort.
\end{itemize}


CI/CD pipelines zijn een essentieel onderdeel van moderne softwareontwikkeling. Ze versnellen de levering van software, verhogen de kwaliteit en betrouwbaarheid, en bevorderen de samenwerking tussen teams. In het kader van datamanagement helpen CI/CD pipelines om data-efficiënte ML-modellen te ontwikkelen en de consistentie en betrouwbaarheid van datastromen te garanderen. Datapipelines spelen een cruciale rol in ML door dataverwerking te automatiseren en de efficiëntie van modeltraining te verhogen.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Machine Learning Pipelines}

Machine learning (ML) is een krachtige technologie die in diverse sectoren wordt toegepast om waardevolle inzichten te verwerven uit data\autocite{Jordan2015}. De ontwikkeling van ML-modellen omvat echter een complexe reeks stappen, van dataverzameling tot modeltraining en -implementatie. Dit proces is vaak repetitief en tijdrovend, wat de efficiëntie en schaalbaarheid van ML-projecten belemmert. Hierdoor worden pipelines gebruikt die het process automatisch laat lopen.


Machine learning pipelines automatiseren en stroomlijnen de stappen in de levenscyclus van ML. De voordelen van pipelines zijn onder andere:
\begin{itemize}
    \item Verhoogde efficiëntie: Pipelines automatiseren repetitieve taken, waardoor de doorlooptijd van ML-projecten wordt verkort.
    \item Verbeterde reproduceerbaarheid: Pipelines garanderen dat experimenten op een consistente manier worden uitgevoerd, waardoor de reproduceerbaarheid van de resultaten wordt gewaarborgd.
    \item Betere schaalbaarheid: Pipelines vergemakkelijken de implementatie van ML-modellen op grotere datasets en in productieomgevingen.
    \item Verhoogde transparantie: Pipelines documenteren de stappen in de ML-workflow, waardoor de transparantie en het begrip van het proces worden vergroot.
\end{itemize}

Pipelines vormen een gestroomlijnde serie geordende stappen die dienen om data te transformeren en modellen te trainen. Deze stappen omvatten data-ingestion, data-preprocessing, feature engineering, modeltraining, modelbeoordeling en modeldeployement. Data-ingestion houdt in het laden van data vanuit diverse bronnen, terwijl data-preprocessing het opschonen, transformeren en normaliseren van de data omvat. Feature engineering richt zich op het selecteren en creëren van features om de data verder te verrijken. Vervolgens wordt het ML-model getraind op basis van de voorbereide data, en worden de prestaties van het model geëvalueerd om de effectiviteit ervan te meten. Ten slotte wordt het model geïmplementeerd in een productieomgeving om operationeel te worden. Pipelines kunnen worden geïmplementeerd met behulp van verschillende tools en frameworks, waaronder Apache Airflow, Kubeflow, TensorFlow Extended (TFX) en Amazon SageMaker. Deze technologieën bieden een gevarieerd scala aan mogelijkheden om de ontwikkeling en implementatie van pipelines te faciliteren en te optimaliseren.


Machine learning pipelines bieden een efficiënte en schaalbare manier om ML-modellen te ontwikkelen en te implementeren. Door de stappen in de levenscyclus van ML te automatiseren, bevorderen pipelines de reproduceerbaarheid, transparantie en efficiëntie van ML-projecten.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Kedro}

In het domein van onderzoek en ontwikkeling op het gebied van Machine Learning (ML) is effectief beheer en opslag van gegevens cruciaal. Kedro, een open-source Python library voor het bouwen van betrouwbare, reproduceerbare en onderhoudbare machine learning-pipelines, komt naar voren als een krachtig instrument voor onderzoekers bij het opzetten en beheren van lokaal uitgevoerde ML-pipelines. Deze scriptie onderzoekt de verdiensten van het gebruik van Kedro in lokale ML-omgevingen en benadrukt de voordelen ervan bij het stroomlijnen van MLOps-praktijken voor onderzoek en scriptieontwikkeling.

Een van de voordelen van het lokaal implementeren van Kedro voor ML-pipelines is de flexibiliteit en modulariteit die het biedt. Kedro maakt het mogelijk om machine learning-pipelines op een flexibele wijze samen te stellen, waardoor onderzoekers gemakkelijk verschillende componenten kunnen toevoegen, verwijderen of aanpassen, afhankelijk van de veranderende behoeften van hun onderzoek.

Een ander belangrijk voordeel is het aspect van versiebeheer en reproduceerbaarheid dat Kedro integreert in ML-pipelines. Dit stelt onderzoekers in staat om experimenten te reproduceren en resultaten te valideren, wat cruciaal is voor het verzekeren van transparantie en betrouwbaarheid in onderzoek.

Daarnaast biedt Kedro een geïntegreerde gegevenscatalogus waarmee onderzoekers gemakkelijk datasets kunnen beheren, documenteren en traceren binnen de ML-pipeline. Dit vereenvoudigt niet alleen het gegevensbeheer, maar bevordert ook de samenwerking tussen teamleden.

Ten slotte, Kedro ondersteunt lokale uitvoering van ML-pipelines, waardoor onderzoekers offline experimenten kunnen uitvoeren en ontwikkelen. Dit is met name gunstig voor onderzoek dat gevoelige gegevens omvat of in situaties waarin cloudresources niet beschikbaar zijn.

Kedro integreert naadloos met populaire ML-frameworks zoals TensorFlow, PyTorch en scikit-learn, waardoor onderzoekers hun favoriete tools kunnen blijven gebruiken binnen de Kedro-pipeline. Dit minimaliseert de leercurve en bevordert een consistente ontwikkelingservaring. Bovendien ondersteunt Kedro het gebruik van virtual environments, waardoor onderzoekers afhankelijkheden kunnen isoleren en een gecontroleerde ontwikkelingsomgeving kunnen behouden. Dit helpt bij het voorkomen van conflicten tussen verschillende projecten en zorgt voor reproduceerbare resultaten.

Een andere geavanceerde functionaliteit van Kedro is de mogelijkheid om automatisch gedetailleerde documentatie voor ML-pipelines te genereren, inclusief informatie over datasets, parameters en dependencies. Dit verbetert de traceerbaarheid en maakt het gemakkelijker om de pipeline te begrijpen en te onderhouden. Daarnaast biedt Kedro tools voor het visualiseren van ML-pipelines, waardoor onderzoekers een overzicht krijgen van de gegevensstroom en de interacties tussen verschillende componenten. Dit vergemakkelijkt het begrip van de pipeline-architectuur en identificeert mogelijke optimalisaties.

Kedro biedt een overtuigende oplossing voor onderzoekers bij het opzetten en beheren van machine learning-pipelines in lokale omgevingen. De flexibiliteit, ondersteuning voor versiebeheer, geïntegreerde gegevenscatalogus en compatibiliteit met populaire ML-frameworks maken het tot een waardevol instrument voor onderzoeksinspanningen. Door gebruik te maken van Kedro kunnen onderzoekers hun ontwikkelingsworkflows stroomlijnen, experimenten reproduceerbaar maken en zich richten op het verkennen van complexe onderzoeksvraagstukken.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textcite{MLflow2023} MLflow is een open-source Python-bibliotheek ontwikkeld door Databricks, die een brede functionaliteit biedt voor het beheren van Machine Learning (ML) projecten. De belangrijkste pijlers van MLflow zijn Tracking, Projects, Models en Registry.

\subsubsection{Tracking}
Tracking biedt een eenvoudige manier om experimenten te volgen en resultaten te vergelijken. MLflow houdt nauwgezet relevante details bij gedurende de ML-levenscyclus, zoals code, parameters, metrieken en artefacten (modellen, datasets), waardoor onderzoekers naadloos eerdere experimenten kunnen reproduceren en verschillende configuraties kunnen vergelijken.

\subsubsection{Projects}
Projects zorgen voor een uniforme structuur voor Machine Learning projecten en bevorderen de herbruikbaarheid. Onderzoekers kunnen gestandaardiseerde projectstructuren definiëren met MLflow Projects, waardoor consistente en reproduceerbare onderzoeksomgevingen worden bevorderd.

\subsubsection{Models}
Models biedt tools om modellen in te pakken en te implementeren in verschillende omgevingen. MLflow stroomlijnt de implementatie van ML-modellen in productieomgevingen door ze te verpakken in een gestandaardiseerd formaat, inclusief de modelcode, afhankelijkheden en configuratiedetails.

\subsubsection{Registry}
Registry fungeert als een centrale hub voor het beheren van modelversies. MLflow stelt onderzoekers in staat om een gecentraliseerd repository in te stellen voor geregistreerde modellen, waardoor ze verschillende versies van modellen kunnen organiseren, volgen en openen.

\subsection{Voordelen van MLflow}

MLflow biedt verschillende voordelen voor onderzoekers in het beheer van Machine Learning projecten:

\begin{itemize}
    \item Verbeterde Reproduceerbaarheid: MLflow's zorgvuldige logging en trackingmogelijkheden zorgen ervoor dat experimenten gemakkelijk reproduceerbaar zijn, wat de geloofwaardigheid en betrouwbaarheid van onderzoek versterkt.
    \item Gestroomlijnde Samenwerking: Gecentraliseerd model- en experimentbeheer bevordert naadloze samenwerking tussen onderzoekers, omdat ze elkaars werk gemakkelijk kunnen delen en volgen.
    \item Verbeterde Efficiëntie: MLflow automatiseert tijdrovende taken zoals experimenttracking en modelbeheer, waardoor onderzoekers waardevolle tijd kunnen vrijmaken voor kernonderzoeksactiviteiten.
    \item Vereenvoudigde Implementatie: MLflow stroomlijnt het implementatieproces, waardoor onderzoekers hun modellen snel en efficiënt kunnen overbrengen van onderzoek naar productieomgevingen.
\end{itemize}

\subsection{Conclusie}

In conclusie, MLflow vestigt zich als een onschatbare troef voor onderzoekers die zich bezighouden met Machine Learning-projecten. Door reproduceerbaarheid te bevorderen, samenwerking te verbeteren en experimentatie, implementatie en beheer te stroomlijnen, stelt MLflow onderzoekers in staat om de kwaliteit en efficiëntie van hun onderzoeksinspanningen te verbeteren.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Kubeflow}

In het domein van onderzoek en ontwikkeling op het gebied van Machine Learning (ML) is effectief beheer en opschaling van machine learning-workloads cruciaal. Kubeflow, een open-source machine learning toolkit ontworpen voor Kubernetes, biedt een krachtige infrastructuur voor onderzoekers bij het opzetten en beheren van machine learning-pipelines in zowel lokale als cloudomgevingen. Deze scriptie onderzoekt de verdiensten van het gebruik van Kubeflow in lokale ML-omgevingen en benadrukt de voordelen ervan bij het stroomlijnen van MLOps-praktijken voor onderzoek en scriptieontwikkeling.

\subsection{Voordelen van Lokale Implementatie van Kubeflow voor ML Pipelines}

\subsubsection{Schaalbaarheid en Flexibiliteit}
Kubeflow maakt gebruik van Kubernetes om machine learning-workloads te beheren, waardoor onderzoekers de mogelijkheid hebben om hun ML-pipelines eenvoudig op te schalen of af te schalen afhankelijk van de behoeften van het onderzoek. Dit maakt het een geschikte keuze voor onderzoeksgroepen van verschillende groottes.

\subsubsection{Geautomatiseerd Beheer}
Met Kubeflow kunnen onderzoekers de implementatie en het beheer van machine learning-pipelines automatiseren, waardoor ze minder tijd hoeven te besteden aan het handmatig configureren en monitoren van infrastructuur. Dit verhoogt de operationele efficiëntie en stelt onderzoekers in staat zich te concentreren op het onderzoek zelf.

\subsubsection{Reproduceerbare Experimenten}
Kubeflow biedt tools en functies voor het vastleggen van de omgeving en het versiebeheer van de code, waardoor onderzoekers experimenten kunnen reproduceren en resultaten kunnen valideren. Dit draagt bij aan de transparantie en betrouwbaarheid van het onderzoek.

\subsubsection{Ondersteuning voor Diverse Workloads}
Kubeflow ondersteunt een breed scala aan machine learning-workloads, waaronder training, inferentie en hyperparameteroptimalisatie, waardoor onderzoekers flexibel kunnen experimenteren met verschillende modellen en technieken binnen dezelfde infrastructuur.

\subsection{Integratie met Lokale ML Tools en Frameworks}

\subsubsection{Naadloze Integratie met Kubernetes}
Kubeflow is ontworpen om naadloos te integreren met Kubernetes, waardoor onderzoekers het gemakkelijk kunnen implementeren en beheren op lokale Kubernetes-clusters. Dit minimaliseert de operationele overhead en bevordert een consistente ontwikkelingservaring.

\subsubsection{Compatibiliteit met ML Frameworks}
Kubeflow biedt integratie met populaire ML-frameworks zoals TensorFlow, PyTorch en scikit-learn, waardoor onderzoekers hun favoriete tools kunnen blijven gebruiken binnen de Kubeflow-pipelines. Dit maximaliseert de flexibiliteit en maakt het gemakkelijk om bestaande modellen en code te hergebruiken.

\subsection{Geavanceerde Functionaliteiten}

\subsubsection{Experiment Tracking en Monitoring}
Kubeflow biedt functionaliteiten voor het bijhouden en monitoren van machine learning-experimenten, waardoor onderzoekers inzicht krijgen in de voortgang van hun onderzoek en potentiële problemen kunnen identificeren. Dit vergemakkelijkt het optimaliseren van de prestaties en het vinden van de beste modellen.

\subsubsection{Model Deployment en Serving}
Kubeflow ondersteunt model deployment en serving, waardoor onderzoekers getrainde modellen gemakkelijk kunnen implementeren en schalen voor productiegebruik. Dit vergemakkelijkt de overgang van experimentele prototypen naar operationele systemen.

\subsection{Conclusie}

Kubeflow biedt een overtuigende oplossing voor onderzoekers bij het opzetten en beheren van machine learning-pipelines in lokale omgevingen. De schaalbaarheid, geautomatiseerd beheer, ondersteuning voor reproduceerbare experimenten en integratie met populaire ML-frameworks maken het tot een waardevol instrument voor onderzoeksinspanningen. Door gebruik te maken van Kubeflow kunnen onderzoekers hun ontwikkelingsworkflows stroomlijnen, experimenten efficiënter uitvoeren en zich richten op het verkennen van complexe onderzoeksvraagstukken.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{ZenML}
ZenML is een open-source framework dat Python-gebaseerde ML pipelines definieert en beheert. Het biedt een end-to-end oplossing voor het ontwikkelen, implementeren en beheren van ML pipelines. ZenML biedt verschillende functies, waaronder:

\begin{itemize}
    \item Opslag van pipelines: ZenML slaat pipelines op in een centrale repository, waardoor ze eenvoudig te hergebruiken en te delen zijn.
    \item Uitvoering van pipelines: ZenML kan pipelines lokaal of op afstand uitvoeren, op verschillende platforms zoals Kubernetes en Docker.
    \item Monitoring van pipelines: ZenML biedt uitgebreide monitoringmogelijkheden om de voortgang en prestaties van pipelines te volgen.
    \item Herstarten van pipelines: ZenML kan pipelines herstarten vanaf een mislukte stap, waardoor fouten eenvoudig te debuggen zijn.
    \item MLOps-functionaliteit: ZenML biedt functies voor MLOps, zoals artefactbeheer, versiebeheer en experimentenbeheer.
\end{itemize}

De voordelen van het gebruik van ZenML voor lokaal uitvoeren van ML pipelines zijn onder andere:

\begin{itemize}
    \item Eenvoudig te gebruiken: ZenML biedt een intuïtieve interface om pipelines te definiëren en te beheren.
    \item Schaalbaar: ZenML kan pipelines uitvoeren op een breed scala aan platforms, van laptops tot clusters.
    \item Flexibel: ZenML kan worden geconfigureerd om te voldoen aan de specifieke behoeften van uw project.
    \item Uitgebreide functies: ZenML biedt een breder scala aan functies dan andere frameworks.
    \item MLOps-gericht: ZenML is ontworpen met MLOps in het achterhoofd, waardoor het een goede keuze is voor teams die MLOps-best practices willen implementeren.
\end{itemize}

\section{Vergelijking met andere Frameworks}
Er zijn verschillende andere frameworks beschikbaar voor het beheren van ML pipelines, waaronder Apache Airflow, Luigi en Kubeflow Pipelines. ZenML onderscheidt zich van deze frameworks door:

\begin{itemize}
    \item Eenvoudig te gebruiken: ZenML heeft een eenvoudiger leercurve dan andere frameworks.
    \item Flexibel: ZenML is meer flexibel in termen van configuratie en aanpassing.
    \item Uitgebreide functies: ZenML biedt een breder scala aan functies dan andere frameworks.
    \item MLOps-gericht: ZenML is uniek in zijn focus op MLOps.
\end{itemize}

ZenML is een krachtig framework voor het beheren en uitvoeren van ML pipelines. Het biedt een scala aan functies, waaronder MLOps-functionaliteit, die het lokaal uitvoeren van pipelines eenvoudig en efficiënt maken. ZenML is een goede keuze voor data scientists en machine learning engineers die een framework zoeken dat gebruiksvriendelijk, schaalbaar, flexibel en MLOps-gericht is.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Prefect}

Prefect is een open-source framework dat Python-gebaseerde ML pipelines definieert als gerichte acyclische grafieken (DAG's). Deze aanpak maakt het mogelijk om de stappen in de pipeline expliciet te definiëren en hun onderlinge afhankelijkheden te specificeren. Het framework biedt een breed scala aan functies voor het beheren en uitvoeren van pipelines, waaronder opslag, uitvoering, monitoring en het herstarten van pipelines vanaf een mislukte stap.

De voordelen van het gebruik van Prefect voor het lokaal uitvoeren van ML pipelines zijn aanzienlijk. Het framework biedt een intuïtieve interface die het gemakkelijk maakt om pipelines te definiëren en te beheren. Daarnaast is Prefect zeer schaalbaar en kan het pipelines uitvoeren op verschillende platforms, variërend van laptops tot clusters. Bovendien is Prefect flexibel configureerbaar om aan de specifieke behoeften van elk project te voldoen.

In vergelijking met andere frameworks voor het beheren van ML pipelines, zoals Apache Airflow, Luigi en Kubeflow Pipelines, onderscheidt Prefect zich door zijn gebruiksvriendelijkheid, flexibiliteit en uitgebreide functieset. Het heeft een eenvoudigere leercurve, is gemakkelijker aan te passen en biedt meer mogelijkheden dan zijn tegenhangers.

Ter afsluiting demonstreren we de praktische toepassing van Prefect met een proof of concept. We definiëren een eenvoudige ML pipeline die een iris-classificatiemodel traint en evalueert, en laten zien hoe deze lokaal kan worden uitgevoerd met Prefect. Deze PoC bevestigt dat Prefect inderdaad een eenvoudige en efficiënte manier biedt om ML pipelines lokaal uit te voeren.

In conclusie is Prefect een krachtig framework voor het beheren en uitvoeren van ML pipelines. Met zijn gebruiksvriendelijke, schaalbare en flexibele karakter is Prefect een uitstekende keuze voor data scientists en machine learning engineers die op zoek zijn naar een betrouwbare oplossing voor het beheren van hun ML workflows.



%%%% Apache Airflow: https://airflow.apache.org/
%%Luigi: https://luigi.readthedocs.io/en/stable/
%%%Kubeflow Pipelines: https://www.kubeflow.org/docs/pipelines/
%%% GITHUB PREFECT EN PREFECT DOCS BRON