\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

%Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

%Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz.\ naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin (narratieve referentie), gebruik je \texttt{$\backslash${}textcite\{\}}. Soms is de auteursnaam niet expliciet een onderdeel van de zin, dan gebruik je \texttt{$\backslash${}autocite\{\}} (referentie tussen haakjes). Dit gebruik je bv.~bij een citaat, of om in het bijschrift van een overgenomen afbeelding, broncode, tabel, enz. te verwijzen naar de bron. In de volgende paragraaf een voorbeeld van elk.

%\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

%Let er ook op: het \texttt{cite}-commando voor de punt, dus binnen de zin. Je verwijst meteen naar een bron in de eerste zin die erop gebaseerd is, dus niet pas op het einde van een paragraaf.
\section{Machine Learning}

Machine Learning (ML) is een onderliggend deel van Artificial Intelligence (AI), een snel groeiend vakgebied op het raakvlak van data en statistiek dat feitgebaseerde beslissingen in verschillende sectoren aanstuurt \autocite{Jordan2015}. Middels het toepassen van wiskundige principes kan Machine Learning verbanden leggen tussen gegevens om betrouwbare voorspellingen te genereren. Dit wordt mogelijk gemaakt door het gebruik van Machine Learning algoritmen, waarmee computers kunnen leren van data. Met gebruik van iteratieve testen en validatie kunnen ze hun prestaties in de loop van de tijd verbeteren, waardoor ze nieuwe taken kunnen uitvoeren met nieuwe data \autocite{Shaveta2023}.

\section{Machine Learning Levenscyclus}

De levenscyclus van een typisch machine learning-project omvat verschillende fasen:

\subsection{Data Verzameling en Preprocessing}
In deze fase worden relevante gegevens verzameld en voorbereid voor analyse. Dit omvat het reinigen van gegevens, het oplossen van ontbrekende waarden en het transformeren van gegevens naar een geschikt formaat voor machine learning-modellen.

\subsection{Model Selectie en Training}
Hier wordt een geschikt machine learning-model geselecteerd op basis van de aard van de gegevens en het doel van het project. Het model wordt vervolgens getraind met behulp van de verzamelde gegevens, waarbij parameters worden aangepast om een optimaal voorspellingsresultaat te bereiken.

\subsection{Validatie en Evaluatie}
Na het trainen van het model wordt het gevalideerd met behulp van een aparte dataset die niet is gebruikt tijdens de training. Dit stelt vast hoe goed het model presteert op nieuwe, niet eerder geziene gegevens.

\subsection{Implementatie en Inzet}
Als het model succesvol is gevalideerd, wordt het geïmplementeerd in de productieomgeving om voorspellingen te genereren op nieuwe gegevens. Dit kan bijvoorbeeld inhouden dat het model wordt geïntegreerd in een bestaande softwareapplicatie of gegevensstroom.

\subsection{Monitoring en Onderhoud}
Nadat het model is ingezet, wordt het continu gemonitord om te controleren op prestatieverlies of achteruitgang in voorspellingsnauwkeurigheid. Indien nodig wordt het model opnieuw getraind met verse gegevens om de prestaties te behouden.

\section{Soorten Machine Learning Methoden}

Er zijn verschillende soorten machine learning-methoden, waaronder:

\subsection{Supervised Learning}
In deze methode wordt het model getraind op een dataset die gelabelde voorbeelden bevat, waarbij het doel is om een voorspellend model te ontwikkelen dat correcte uitvoer kan genereren voor nieuwe, niet eerder geziene gegevens.

\subsection{Unsupervised Learning}
Hierbij wordt het model getraind op een dataset zonder gelabelde voorbeelden. Het doel is om patronen en structuren in de gegevens te ontdekken zonder voorafgaande kennis van de uitvoer.

\subsection{Semi-supervised Learning}
Deze methode maakt gebruik van een combinatie van gelabelde en ongelabelde gegevens voor training. Het model profiteert van zowel de begeleide als de onbegeleide informatie om nauwkeuriger voorspellingen te maken.

\subsection{Reinforcement Learning}
Bij reinforcement learning leert het model door interactie met een dynamische omgeving, waarbij het beloningen ontvangt of straffen krijgt op basis van de acties die het uitvoert. Het doel is om een optimale strategie te ontwikkelen om de ontvangen beloningen te maximaliseren.

\subsection{Deep Learning}
Deep learning is een subset van machine learning die gebruikmaakt van kunstmatige neurale netwerken met meerdere lagen van verwerkingseenheden om complexe patronen in grote datasets te leren en te begrijpen.

\section{Conclusie}

Machine learning speelt een cruciale rol in het genereren van inzichten uit gegevens en het maken van voorspellingen op basis van complexe patronen. Door de levenscyclus van machine learning-projecten te begrijpen en verschillende soorten machine learning-methoden te verkennen, kunnen onderzoekers en ontwikkelaars effectievere en nauwkeurigere modellen ontwikkelen om een breed scala aan problemen op te lossen.

\section{MLFlow}

\textcite{MLflow2023} benadrukt gebruiksgemak en aanpasbaarheid. Het biedt een gestandaardiseerde manier om Machine Learning projecten te beheren, ongeacht de programmeertaal die wordt gebruikt. Met MLflow kunnen experimenten worden bijgehouden, modelparameters worden geregistreerd, modellen worden beheerd en zelfs modellen worden geïmplementeerd in verschillende omgevingen.

\section{MLflow: Een Overzicht}

MLflow is een open-source Python-bibliotheek ontwikkeld door Databricks, die een brede functionaliteit biedt voor het beheren van Machine Learning (ML) projecten. De belangrijkste pijlers van MLflow zijn Tracking, Projects, Models en Registry.

\subsection{Tracking}
Tracking biedt een eenvoudige manier om experimenten te volgen en resultaten te vergelijken. MLflow houdt nauwgezet relevante details bij gedurende de ML-levenscyclus, zoals code, parameters, metrieken en artefacten (modellen, datasets), waardoor onderzoekers naadloos eerdere experimenten kunnen reproduceren en verschillende configuraties kunnen vergelijken.

\subsection{Projects}
Projects zorgen voor een uniforme structuur voor Machine Learning projecten en bevorderen de herbruikbaarheid. Onderzoekers kunnen gestandaardiseerde projectstructuren definiëren met MLflow Projects, waardoor consistente en reproduceerbare onderzoeksomgevingen worden bevorderd.

\subsection{Models}
Models biedt tools om modellen in te pakken en te implementeren in verschillende omgevingen. MLflow stroomlijnt de implementatie van ML-modellen in productieomgevingen door ze te verpakken in een gestandaardiseerd formaat, inclusief de modelcode, afhankelijkheden en configuratiedetails.

\subsection{Registry}
Registry fungeert als een centrale hub voor het beheren van modelversies. MLflow stelt onderzoekers in staat om een gecentraliseerd repository in te stellen voor geregistreerde modellen, waardoor ze verschillende versies van modellen kunnen organiseren, volgen en openen.

\section{Voordelen van MLflow}

MLflow biedt verschillende voordelen voor onderzoekers in het beheer van Machine Learning projecten:

\begin{itemize}
    \item Verbeterde Reproduceerbaarheid: MLflow's zorgvuldige logging en trackingmogelijkheden zorgen ervoor dat experimenten gemakkelijk reproduceerbaar zijn, wat de geloofwaardigheid en betrouwbaarheid van onderzoek versterkt.
    \item Gestroomlijnde Samenwerking: Gecentraliseerd model- en experimentbeheer bevordert naadloze samenwerking tussen onderzoekers, omdat ze elkaars werk gemakkelijk kunnen delen en volgen.
    \item Verbeterde Efficiëntie: MLflow automatiseert tijdrovende taken zoals experimenttracking en modelbeheer, waardoor onderzoekers waardevolle tijd kunnen vrijmaken voor kernonderzoeksactiviteiten.
    \item Vereenvoudigde Implementatie: MLflow stroomlijnt het implementatieproces, waardoor onderzoekers hun modellen snel en efficiënt kunnen overbrengen van onderzoek naar productieomgevingen.
\end{itemize}

\section{Conclusie}

In conclusie, MLflow vestigt zich als een onschatbare troef voor onderzoekers die zich bezighouden met Machine Learning-projecten. Door reproduceerbaarheid te bevorderen, samenwerking te verbeteren en experimentatie, implementatie en beheer te stroomlijnen, stelt MLflow onderzoekers in staat om de kwaliteit en efficiëntie van hun onderzoeksinspanningen te verbeteren.


\section{Minio}

In het domein van onderzoek en ontwikkeling op het gebied van Machine Learning (ML) is effectief beheer en opslag van gegevens cruciaal. Minio, een open-source, high-performance objectopslagoplossing, komt naar voren als een krachtig instrument voor onderzoekers bij het opzetten en beheren van lokaal uitgevoerde ML-pipelines. Deze scriptie onderzoekt de verdiensten van het gebruik van Minio in lokale ML-omgevingen en benadrukt de voordelen ervan bij het stroomlijnen van MLOps-praktijken voor onderzoek en scriptieontwikkeling.

\section{Voordelen van Lokale Implementatie van Minio voor ML Pipelines}

\subsection{Kosteneffectieve Opslag}
Minio elimineert licentiekosten die gepaard gaan met eigen oplossingen, waardoor het een budgetvriendelijke optie is voor onderzoeksprojecten. Dit is met name gunstig voor kleinere onderzoeksgroepen of individuen met beperkte middelen.

\subsection{Vereenvoudigd Gegevensbeheer}
Minio's op objecten gebaseerde opslag vereenvoudigt het gegevensbeheer voor ML-pipelines. Elk gegevenspunt wordt opgeslagen als een onveranderlijk object met een unieke identifier, waardoor directe toegang en versiebeheer mogelijk zijn. Dit vereenvoudigt de gegevensopvraging en de reproduceerbaarheid van experimenten, cruciale aspecten van onderzoek.

\subsection{Schaalbaarheid en Flexibiliteit}
De horizontale schaalbaarheid van Minio stelt onderzoekers in staat om de opslagcapaciteit geleidelijk te vergroten naarmate hun datavolume groeit. Deze aanpasbaarheid zorgt ervoor dat de opslagoplossing kan voldoen aan de evoluerende behoeften van onderzoeksprojecten.

\subsection{Offline Experimenten}
Minio stelt onderzoekers in staat om ML-pipelines uit te voeren en gegevens volledig lokaal op te slaan, waardoor offline experimenten en ontwikkeling mogelijk zijn. Dit is met name voordelig voor onderzoek met gevoelige gegevens die niet op cloudplatforms kunnen worden opgeslagen vanwege privacy- of beveiligingsproblemen.

\section{Integratie met Lokale ML Tools en Frameworks}

\subsection{Docker en Kubernetes}
Minio kan eenvoudig worden gecontaineriseerd met behulp van Docker en worden ingezet op lokale Kubernetes-clusters, waardoor onderzoekers het naadloos kunnen integreren in hun bestaande lokale ontwikkelings- en implementatieomgeving. Dit vergemakkelijkt een consistente workflow voor zowel lokale ontwikkeling als mogelijke toekomstige cloudimplementatie.

\subsection{ML Frameworks}
Minio integreert met populaire ML-frameworks zoals TensorFlow en PyTorch via hun objectopslag-API's, waardoor onderzoekers direct toegang hebben tot en gegevens kunnen verwerken die zijn opgeslagen in Minio met behulp van vertrouwde tools. Dit vereenvoudigt het gegevensbeheer binnen de ML-pipeline.

\section{Geavanceerde Functionaliteiten}

\subsection{Beveiligingsfuncties}
Minio biedt verschillende beveiligingsfuncties, waaronder gebruikersauthenticatie, toegangscontrole en versleuteling, waardoor de vertrouwelijkheid en integriteit van onderzoeksgegevens zelfs in een lokale omgeving worden gewaarborgd. Het implementeren van passende beveiligingsmaatregelen is cruciaal voor het beschermen van gevoelige onderzoeksgegevens.

\subsection{Gegevenslevenscyclusbeheer}
Minio stelt onderzoekers in staat om beleidsregels voor gegevenslevenscyclus te definiëren, zoals het automatisch archiveren van oudere gegevens of het verwijderen van tijdelijke bestanden. Dit helpt bij het handhaven van een efficiënt gebruik van opslagruimte en voorkomt gegevensrommel binnen de lokale omgeving.

\subsection{Monitoring en Observatie}
Minio biedt monitoringtools en API's om opslaggebruik bij te houden, potentiële problemen te identificeren en inzicht te krijgen in gegevenstoegangspatronen. Deze informatie kan waardevol zijn voor het optimaliseren van de lokale opslagconfiguratie en het zorgen voor een soepele werking van ML-pipelines.

\section{Conclusie}

Minio biedt een overtuigende oplossing voor onderzoekers bij het opzetten en beheren van gegevensopslag voor lokaal uitgevoerde ML-pipelines. De kosteneffectiviteit, het gemak van beheer, de schaalbaarheid en de offline mogelijkheden maken het tot een waardevol instrument voor onderzoeksinspanningen, waardoor efficiënte MLOps-praktijken worden bevorderd en reproduceerbaar onderzoek wordt vergemakkelijkt. Door gebruik te maken van Minio kunnen onderzoekers hun lokale ontwikkelingsworkflows stroomlijnen en zich richten op kernonderzoeksactiviteiten.

\section{Apache Beam}

De exponentiële groei van gegevens in diverse formaten stelt organisaties voor aanzienlijke uitdagingen bij het extraheren van zinvolle inzichten {BRON}. Apache Beam heeft zich ontwikkeld tot een overtuigende oplossing, met een uniform programmeringsmodel dat ontwikkelaars in staat stelt schaalbare, fouttolerante gegevensverwerkingspipelines te construeren die zowel batch- als real-time streaminggegevens kunnen verwerken. Deze scriptie onderzoekt de verdiensten van Apache Beam, met name de geschiktheid ervan voor verschillende toepassingen voor het verwerken van big data, waarbij de voordelen ervan worden benadrukt in de context van onderzoek en scriptieontwikkeling.

\section{Uniform Programmeringsmodel}

De kernkracht van Apache Beam ligt in zijn abstractie van onderliggende infrastructuur, waardoor ontwikkelaars zich kunnen concentreren op logische gegevenstransformaties in plaats van te worden gehinderd door implementatiedetails op laag niveau. Deze abstractielaag presenteert een draagbaar programmeringsmodel, waardoor ontwikkelaars code kunnen schrijven die onafhankelijk is van de bron en uitvoerder. In eenvoudiger bewoordingen:
\begin{itemize}
    \item Source-agnostic: Code blijft onafhankelijk van de gegevensbron (bijv. databases, berichtenwachtrijen, bestanden), waardoor gemakkelijk kan worden geschakeld tussen verschillende gegevensbronnen zonder significante codeaanpassingen.
    \item Runner-agnostic: Code blijft onafhankelijk van het onderliggende uitvoeringsplatform (bijv. Apache Flink, Apache Spark, Google Cloud Dataflow), waardoor dezelfde pipelinecode naadloos op verschillende platforms kan worden uitgevoerd.
\end{itemize}

\section{Belangrijkste Functionaliteiten}

\subsection{Gegevenstransformaties}
Beam's kernkracht ligt in zijn rijke set van primitieve transformaties (bijv. filtering, mapping, aggregatie) die aan elkaar kunnen worden gekoppeld om complexe gegevensverwerkingspipelines te vormen.

\subsection{Windowing}
Beam vergemakkelijkt de verwerking van gegevensstromen door ze in eindige vensters te verdelen, waardoor ontwikkelaars gegevens in stukken in de tijd kunnen analyseren. Dit is cruciaal voor real-time toepassingen waarbij het continu analyseren van de volledige stroom niet haalbaar is.

\subsection{State Management}
Beam ondersteunt het beheren van staat (bijv. bijhouden van tussentijdse resultaten) over verschillende verwerkingsunits, waardoor complexe berekeningen mogelijk zijn waarbij historische informatie wordt bijgehouden.

\subsection{Fouttolerantie}
Beam-pipelines zijn inherent fouttolerant en behandelen automatisch storingen en herstellen daarvan zonder gegevensverlies. Dit zorgt voor betrouwbare verwerking, zelfs bij systeemproblemen.

\section{Voordelen}

\subsection{Stream Processing}
Beam is bijzonder geschikt voor onderzoeksgebieden die te maken hebben met real-time gegevensstromen. Bijvoorbeeld, onderzoekers kunnen Beam gebruiken om sensorgegevens van experimenten te analyseren, financiële transacties in realtime te verwerken, of socialemediastromen te analyseren om realtime trends te bestuderen.

\subsection{Schaalbaarheid}
Beam-pipelines kunnen horizontaal worden geschaald door meer verwerkingswerkers toe te voegen, waardoor onderzoekers efficiënt met grootschalige gegevens kunnen omgaan. Deze aanpasbaarheid is cruciaal voor het omgaan met het groeiende volume aan gegevens in veel onderzoeksprojecten.

\subsection{Flexibiliteit}
De bron-onafhankelijke aard van Beam stelt onderzoekers in staat om gemakkelijk te schakelen tussen verschillende gegevensbronnen zonder belangrijke codeaanpassingen, waardoor experimenten met diverse datasets worden gestimuleerd.

\subsection{Reproduceerbaarheid}
Het draagbare programmeringsmodel van Beam bevordert de reproduceerbaarheid, aangezien code gemakkelijk kan worden gedeeld en uitgevoerd op verschillende platforms, waardoor samenwerking en verificatie van onderzoeksresultaten worden vergemakkelijkt.

\section{Integratie met Bestaande Systemen}

Beam integreert naadloos met verschillende populaire big data-platforms en -tools:

\subsection{Cloudplatforms}
Beam-pipelines kunnen worden uitgevoerd op toonaangevende cloudplatforms zoals Google Cloud Platform (GCP), Amazon Web Services (AWS) en Microsoft Azure, waarbij gebruik wordt gemaakt van de kracht van cloudresources voor efficiënte en schaalbare gegevensverwerking.

\subsection{Opslagsystemen}
Beam-pipelines kunnen eenvoudig gegevens lezen van en schrijven naar populaire opslagsystemen zoals Apache HDFS, Amazon S3 en Google Cloud Storage, waardoor flexibiliteit in gegevenstoegang en -beheer wordt geboden.

\subsection{Machine Learning Frameworks}
Integratie met frameworks zoals TensorFlow, PyTorch en scikit-learn stelt onderzoekers in staat om machine learning-modellen naadloos op te nemen in hun gegevensverwerkingspipelines, waardoor taken zoals realtime anomaliedetectie, sentimentanalyse of voorspellende modellering op streaminggegevens mogelijk worden.

\section{Verder dan de Basis}

\subsection{Apache Beam SQL}
Beam biedt een SQL-achtige interface voor het schrijven van gegevensverwerkingspipelines, als alternatief voor gebruikers die bekend zijn met SQL-syntax.

\subsection{User-Defined Functions (UDFs)}
Beam stelt ontwikkelaars in staat om hun eigen aangepaste functies (UDFs) te definiëren in Python, Java of Go, waardoor de implementatie van specifieke verwerkingslogica op maat van onderzoeksproblemen mogelijk is.

\subsection{Testen en Debuggen}
Beam biedt verschillende tools en frameworks voor het testen en debuggen van pipelines, waardoor de juistheid en robuustheid van onderzoeksresultaten worden gegarandeerd.

\section{Conclusie}

Apache Beam biedt een overtuigend programmeermodel voor het construeren van robuuste, schaalbare en fouttolerante gegevensverwerkingspipelines die zowel batch- als real-time streaminggegevens kunnen verwerken. Zijn bron- en uitvoerder-agnostische aard, gekoppeld aan zijn rijke set functies en naadloze integratie met populaire big data-tools, maken het tot een onschatbaar hulpmiddel voor onderzoekers die werken met grootschalige gegevens in verschillende domeinen. Door Beam te benutten, kunnen onderzoekers zich concentreren op de kernlogica van hun onderzoek terwijl ze profiteren van de abstractie- en uitvoeringsmogelijkheden van het platform.