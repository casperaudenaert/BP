%---------- Inleiding ---------------------------------------------------------

\section{Introductie}%
\label{sec:introductie}

De toename van Artificiële Intelligentie (AI), Machine Learning (ML) en Deep Learning heeft geleid tot een groeiende vraag naar manieren om machine learning modellen op een schaalbare en efficiënte manier te implementeren en te beheren.
Binnen het keuzepakket ``AI \& Data Engineering'' legt het opleidingsonderdeel Machine Learning Operations, waar studenten leren van over opzetten van machine learning workspaces tot het monitoren van machine learning operations.
Dit onderzoek richt zich op een specifieke uitdaging binnen Machine Learning Operations: Het lokaal uitvoeren van machine learning pipelines.\newline

In deze context wordt er gebruik gemaakt van Azure ML pipelines, waarvan het onderliggende framework Kubeflow is. Kubeflow is een open-source machine learning toolkit op Kubernetes \autocite{Kubeflow2021}.
Het gebruik van Azure ML pipelines is namelijk niet gratis voor studenten die niet genoeg krediet hebben op het platform. Hierdoor richt dit onderzoek zich op het lokaal uitvoeren van machine learning pipelines.
Het lokaal uitvoeren van machine learning pipelines kan ook problemen met zich meebrengen, zoals de noodzaak van veel rekenkracht die mogelijk niet beschikbaar is op lokale computers. Als gevolg daarvan hebben bepaalde frameworks een beperkte versie die niet zo krachtig is als de cloud, maar toch lokaal machine learning pipelines kan uitvoeren.
Er zal onderzoek worden gedaan naar alternatieve frameworks om Machine Learning pipelines lokaal uit te voeren, zoals Kubeflow, Kedro en MLflow. Deze zullen dan met elkaar worden vergeleken om een Proof of Concept (PoC) op te stellen. Hierbij zal gekeken worden naar hoe de verschillende frameworks en bibliotheken werken, welke programmeertaal ze gebruiken en de verschillende functies van elk framework.
Daarnaast worden de frameworks ook getest op de compatibiliteit met verschillende besturingssystemen (OS). Deze test omvat gedetailleerde installaties van alle frameworks, waarvan de resultaten worden vastgelegd in een rapport.\newline

Dit onderzoek richt zich op IT-professionals die betrokken zijn bij Machine Learning Operations, specifiek voor de diegenen die ML-pipelines lokaal willen uitvoeren.
Het lokaal uitvoeren van machine learning pipelines blijkt een uitdaging te zijn, vooral met betrekking tot de huidige migratieproblemen en gebrekkige documentatie.
De centrale probleemstelling is daarom: "Hoe kan een ML-pipeline lokaal worden uitgevoerd met behulp van een machine learning framework?"

%---------- Stand van zaken ---------------------------------------------------

\section{Literatuurstudie}%
\label{sec:state-of-the-art}
De exponentiële groei van machine learning heeft niet alleen het onderzoeksdomein beïnvloed, maar heeft ook de implementatie van machine learning pipelines tot leven gebracht.
Deze literatuurstudie werpt een diepgaande blik op het lokaal uitvoeren van machine learning pipelines door middel van een vergelijkende studie en een proof of concept.
De focus van deze literatuurstudie zal liggen op de fundamentele elementen van machine learning pipelines, zoals de definitie van machine learning en pipelines, evenals een overzicht van de beschikbare frameworks voor het lokale uitvoeren van machine learning pipelines.
\subsection{Machine Learning}
Machine Learning (ML) is een onderliggend deel van Artificiële Intelligentie (AI), een snel groeiend vakgebied op het raakvlak van informatie en statistiek dat feit gebaseerde beslissingen in verschillende sectoren aanstuurt \autocite{Jordan2015}.
Middels het toepassen van wiskundige principes kan machine learning verbanden leggen tussen gegevens om betrouwbare voorspellingen te genereren. Dit wordt mogelijk gemaakt door het gebruik van machine learning algoritmen, waarmee computers kunnen leren van data. Met gebruik van iteratieve testen en validatie kunnen ze hun prestaties in de loop van de tijd verbeteren, waardoor ze nieuwe taken kunnen uitvoeren met nieuwe data \autocite{Shaveta2023}.
\subsection{CI/CD pipelines}
Een CI/CD (Continuous Integration/Continuous Deployment, soms ook Continuous Delivery genoemd) is een cruciaal onderdeel van moderne softwareontwikkeling, voor een snellere en meer betrouwbare levering van web applicaties\\ \autocite{Singh2023}.
De effectiviteit van deze pipelines hangt sterk af van het juiste onderhoud en updates om in lijn te blijven met de veranderingen in systemen en technologieën.
Binnen het domein van datamanagement beklemtonen \autocite{Samad2018} en \autocite{RMV2020} de cruciale aspecten van respectievelijk het optimaliseren van beperkte data samples en de implementatie van Continuous Integration in de datapipeline.
Deze inzichten vormen de kern van een intrigerende verhaallijn die draait om de zoektocht naar efficiëntie en effectiviteit bij het omgaan met gegevens. In deze studies wordt ook aangetoond dat het verzamelen van data veel geld kan kosten en veel tijd in beslag kan nemen. De studies tonen aan dat je met behulp van ML-pipelines met een beperkte dataset ook nauwkeurige modellen kunt genereren.
In dit onderzoeksvoorstel treed ook \citeauthor{Zhang2022} \autocite{Zhang2022} naar voren als een belangrijk figuur met zijn eigen bijdragen.
Zhang richt zich op het ontwerpen en automatiseren van data pipelines. Hij toont aan dat met behulp van datapipelines een machine learning model veel efficiënter kan worden getraind, omdat de data goed wordt schoongemaakt en verwerkt, zodat onnodige of ontbrekende data niet de accuraatheid van het model beinvloed.
Deze drie experten vormen samen een intrigerend plot, waarin het optimaliseren van data samples, Continuous Integration, automatisering van datapijplijnen en geavanceerde technologieën als symbolische planning en reinforcement learning centraal staan. 
\subsection{Frameworks}
Een framework in programmeren is een herbruikbaar ontwerp, uitgedrukt als een reeks abstracte klassen en hun interacties \autocite{JuhaHautamaeki1997}. Dit essentiële concept heeft de potentie om het softwareontwikkelingsproces aanzienlijk te verbeteren door ontwikkelaars de flexibiliteit te bieden om het gedrag ervan aan te passen aan de specifieke vereisten van hun huidige project \autocite{JuhaHautamaeki1997}. Het framework maakt het mogelijk om zowel het ontwerp als de code opnieuw te gebruiken, waardoor ontwikkelaars de kosten van het ontwikkelen van een toepassing kunnen verminderen. Deze benadering bevordert niet alleen de efficiëntie van het ontwikkelproces, maar zorgt ook voor een gestroomlijnde en kosteneffectieve aanpak in \\software-engineering. Het vermogen om herhaaldelijk gebruik te maken van reeds bestaande ontwerppatronen en interacties in verschillende projecten resulteert in een aanzienlijke tijds- en kostenefficiëntie, terwijl het ook bijdraagt aan de consistentie en kwaliteit van de ontwikkelde software.
\subsection{Bibliotheken}
Programmeerbibliotheken zijn verzamelingen van vooraf geschreven code die hergebruikt kunnen worden om het ontwikkelingsproces te vereenvoudigen. Ze kunnen gebruikt worden voor verschillende taken, zoals het ophalen van documenten, sorteren en indexeren, en softwareontwikkeling.
\subsection{Kubeflow}
Kubeflow is een open-source platform dat een collectie van machine learning tools biedt die compatibel zijn met Kubernetes \autocite{Stein2020}. Het wordt vooral gebruikt in DevOps-frameworks, waar het machine learning stacks en componenten zoals PyTorch en TensorFlow kan beheren \autocite{NGC2021}.
Kubeflow kan ook gebruikt worden van end-to-end machine learning-oplossingen, waarbij pipeline-onderdelen de uitvoering van taken en het beheer van artefacten vereenvoudigen \autocite{Bisong2019}.
Met Kubeflow kunnen teams profiteren van herbruikbare ML-componenten, zoals TensorFlow en PyTorch, terwijl ze tegelijkertijd gebruikmaken van Kubernetes-voorzieningen voor schaalbaarheid, betrouwbaarheid en flexibiliteit. Deze samenwerking tussen Kubernetes en Kubeflow stelt organisaties in staat om machine learning-processen te versnellen en te vereenvoudigen, waardoor ze snel kunnen reageren op de eisen van een dynamische markt.
\subsection{Kedro}
Kedro biedt een gestructureerde aanpak voor het bouwen van data-pipelines door gebruik te maken van best practices en industriestandaarden. Met Kedro kunnen data engineers op een collaboratieve en efficiënte manier werken aan projecten, vanaf de initiële data-inname tot aan de implementatie van geavanceerde machine learning modellen.
De kracht van Kedro ligt in zijn flexibiliteit en modulariteit. Het framework is gebaseerd op een component gebaseerde architectuur, waardoor gebruikers gemakkelijk herbruikbare en onderhoudbare code kunnen creëren. Of je nu een beginner bent in data engineering of een ervaren professional, Kedro maakt het mogelijk om op een gestructureerde manier te werken aan complexe data-pipelines, waardoor de ontwikkelingstijd wordt verkort en de betrouwbaarheid van data-pipelines wordt verbeterd.
\subsection{MLflow}
MLflow, legt de nadruk op eenvoud en flexibiliteit. Het voorziet in een gestandaardiseerde manier om machine learning projecten te organiseren, ongeacht de gebruikte programmeertaal. Met MLflow kunnen gebruikers moeiteloos experimenten registreren, modelparameters volgen, modellen versiebeheer uitvoeren en zelfs modellen implementeren in verschillende omgevingen.
De belangrijkste pijlers van MLflow omvatten Tracking, Projects, Models en Registry. Tracking biedt een eenvoudige manier om experimenten bij te houden en resultaten te vergelijken.
Projects standaardiseren de structuur van machine learning projecten en vergemakkelijken de herbruikbaarheid.
Models biedt hulpmiddelen voor het verpakken van modellen en implementatie in verschillende omgevingen, terwijl Registry een gecentraliseerde hub is voor het beheer van modelversies.

%Hier beschrijf je de \emph{state-of-the-art} rondom je gekozen onderzoeksdomein, d.w.z.\ een inleidende, doorlopende tekst over het onderzoeksdomein van je bachelorproef. Je steunt daarbij heel sterk op de professionele \emph{vakliteratuur}, en niet zozeer op populariserende teksten voor een breed publiek. Wat is de huidige stand van zaken in dit domein, en wat zijn nog eventuele open vragen (die misschien de aanleiding waren tot je onderzoeksvraag!)?

%Je mag de titel van deze sectie ook aanpassen (literatuurstudie, stand van zaken, enz.). Zijn er al gelijkaardige onderzoeken gevoerd? Wat concluderen ze? Wat is het verschil met jouw onderzoek?

%Verwijs bij elke introductie van een term of bewering over het domein naar de vakliteratuur, bijvoorbeeld~\autocite{Hykes2013}! Denk zeker goed na welke werken je refereert en waarom.

%Draag zorg voor correcte literatuurverwijzingen! Een bronvermelding hoort thuis \emph{binnen} de zin waar je je op die bron baseert, dus niet er buiten! Maak meteen een verwijzing als je gebruik maakt van een bron. Doe dit dus \emph{niet} aan het einde van een lange paragraaf. Baseer nooit teveel aansluitende tekst op eenzelfde bron.

%Als je informatie over bronnen verzamelt in JabRef, zorg er dan voor dat alle nodige info aanwezig is om de bron terug te vinden (zoals uitvoerig besproken in de lessen Research Methods).

% Voor literatuurverwijzingen zijn er twee belangrijke commando's:
% \autocite{KEY} => (Auteur, jaartal) Gebruik dit als de naam van de auteur
%   geen onderdeel is van de zin.
% \textcite{KEY} => Auteur (jaartal)  Gebruik dit als de auteursnaam wel een
%   functie heeft in de zin (bv. ``Uit onderzoek door Doll & Hill (1954) bleek
%   ...'')

%Je mag deze sectie nog verder onderverdelen in subsecties als dit de structuur van de tekst kan verduidelijken.

%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

\subsection{Fase 1: Literatuurstudie (3 weken)}
Het onderzoek zal bestaan uit verschillende fasen. Er zal eerst een literatuurstudie worden uitgevoerd om inzicht te krijgen in de werking en
functies van verschillende frameworks en bibliotheken die machine learning pipelines ondersteunen.
Deze literatuurstudie zal gericht zijn op het vaststellen van mogelijke manieren om machine learning pipelines lokaal te uitvoeren. Er zal ook gekeken worden naar de gelijkenissen en verschillen van de frameworks en de compatibiliteit met verschillende Operating Systems (OS) zoals Windows, Linux en MacOS
Als resultaat zal een samenvatting geschreven worden met alle relevante informatie voor dit onderzoek.
Er wordt ook een requirementsanalayse opgesteld.\\
\subsection{Fase 3: Long list (2 weken)}
Binnen deze fase wordt een longlist van mogelijke bronnen samengesteld die potentieel bruikbaar kunnen zijn. Een methodologie gericht op
grondig online onderzoek, alsook het doorzoeken
van diverse frameworks en bibliotheken, wordt
gehanteerd om een omvangrijke lijst van bronnen te verzamelen. Deze bronnen zijn geselecteerd vanwege hun potentie om waardevolle informatie te verschaffen die relevant is voor het vergelijken van de frameworks.
\subsection{Fase 4: Short list (1 weken)}
Gebruikmakend van de longlist, zullen de
bronnen geëvalueerd en gerangschikt worden
op grond van hun praktische toepasbaarheid.
Deze procedure zal resulteren in het vormen van
een beknopte lijst van waardevolle bronnen. Dit
stelt ons in staat om duplicatie van informatie te
vermijden, aangezien we geen meerdere bronnen met identieke informatie zullen opnemen.
\subsection{Fase 5: Kiezen van de gepaste frameworks (2 weken)}
In deze stap worden de geschikte frameworks gekozen gebaseerd op de requirements.
\subsection{Fase 6: Het maken van een ML-pipeline (2 weken)}
Het testen van de frameworks zal gebeuren met 
\subsection{Fase 7: Proof of Concept (2 weken)}
Het proof of concept zal bestaan uit testen die worden uitgevoerd op de gekozen frameworks. Eerst zal de installatie zal worden uitgevoerd en elke stap zal beschreven en geanalyseerd worden om in kaart te brengen of er fouten voor komen. Daarnaast wordt er gekeken hoe er machine learning pipelines lokaal worden uitgevoerd. Hiervoor zal er een pipeline gemaakt worden die altijd dezelfde data verwerkt en bewerkingen uitvoert. Dit resultaat zal worden bijgehouden in een rapport.
Deze testen zullen op verschillende besturingssystemen worden uitgevoerd zoals Windows macOS en met verschillende soorten data. Hierdoor zal dit onderzoek over meer data beschikken en zullen de uiteindelijke conclusies beter onderbouwd kunnen worden.\\

Na het verzamelen van de nodige data van de verschillende testen wordt dit ook verder geanalyseerd. Dit zal gebeuren door de resultaten van de verschillende testen te vergelijken. 
De data die zal verzameld worden van de testen zijn:
\begin{itemize}
  \item Hoe is de installatie of gebuik van de frameworks and bibliotheken verlopen?
  \item Hoelang duurde de installatie.
  \item Hoe word de zelfde pipeline uitgevoerd op de verschillende frameworks en bibliotheken.
  \item Hoelang duurde het uitvoeren van de pipelines op de verschillende frameworks en bibliotheken.
  \item Er word gekeken of alle requirements uit de requirementsanalyse behaald zijn.
\end{itemize}
Op deze manier wordt er gekeken hoe effectief de verschillende frameworks en bibliotheken de machine learning pipelines lokaal kunnen uitvoeren. Tot slot wordt op basis van de geanalyseerde data een conclusie geformuleerd.\\
\subsection{Fase 8: Conclusie (2 weken)}
Het uiteindelijke resultaat van dit onderzoek zal een volledig rapport zijn waarin de bevindingen en conclusies gedetailleerd beschreven worden alsook een oplossing voor het lokaal uitvoeren van machine learning pipelines. Dit zal stapsgewijs gebeuren, waarin de belangrijkste bevindingen en conclusies worden aangetoond.\\

\begin{tikzpicture}[node distance=2cm, every node/.style={font=\small}]
  \node (pro0) [rectangle, draw, minimum width=3cm, minimum height=1cm, text centered, text width=3cm] {Literatuurstudie};
  \node (pro1) [rectangle, draw, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, below of=pro0] {Onderzoek naar het lokaal uitvoeren van Kubeflow pipelines};
  \node (pro2) [rectangle, draw, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, right of=pro1, xshift=2cm] {Onderzoek verschillende frameworks en libraries en hun werking};
  \node (pro3) [rectangle, draw, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, below of=pro1] {Opstellen Short list};
  \node (pro4) [rectangle, draw, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, below of=pro3] {Testen van het lokaal uitvoeren van machine learning pipelines};
  \node (pro5) [rectangle, draw, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, below of=pro4] {Analyseren en vergelijken van resultaten};
  \node (pro6) [rectangle, draw, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, below of=pro5] {Scriptie};

  \draw [->] (pro0) -- (pro1);
  \draw [->] (pro0) -- (pro2);
  \draw [->] (pro2) -- (pro3);
  \draw [->] (pro1) -- (pro3);
  \draw [->] (pro3) -- (pro4);
  \draw [->] (pro4) -- (pro5);
  \draw [->] (pro5) -- (pro6);
\end{tikzpicture}


%Hier beschrijf je hoe je van plan bent het onderzoek te voeren. Welke onderzoekstechniek ga je toepassen om elk van je onderzoeksvragen te beantwoorden? Gebruik je hiervoor literatuurstudie, interviews met belanghebbenden (bv.~voor requirements-analyse), experimenten, simulaties, vergelijkende studie, risico-analyse, PoC, \ldots?

%Valt je onderwerp onder één van de typische soorten bachelorproeven die besproken zijn in de lessen Research Methods (bv.\ vergelijkende studie of risico-analyse)? Zorg er dan ook voor dat we duidelijk de verschillende stappen terug vinden die we verwachten in dit soort onderzoek!

%Vermijd onderzoekstechnieken die geen objectieve, meetbare resultaten kunnen opleveren. Enquêtes, bijvoorbeeld, zijn voor een bachelorproef informatica meestal \textbf{niet geschikt}. De antwoorden zijn eerder meningen dan feiten en in de praktijk blijkt het ook bijzonder moeilijk om voldoende respondenten te vinden. Studenten die een enquête willen voeren, hebben meestal ook geen goede definitie van de populatie, waardoor ook niet kan aangetoond worden dat eventuele resultaten representatief zijn.

%Uit dit onderdeel moet duidelijk naar voor komen dat je bachelorproef ook technisch voldoen\-de diepgang zal bevatten. Het zou niet kloppen als een bachelorproef informatica ook door bv.\ een student marketing zou kunnen uitgevoerd worden.

%Je beschrijft ook al welke tools (hardware, software, diensten, \ldots) je denkt hiervoor te gebruiken of te ontwikkelen.

%Probeer ook een tijdschatting te maken. Hoe lang zal je met elke fase van je onderzoek bezig zijn en wat zijn de concrete \emph{deliverables} in elke fase?

%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat, conclusie}%
\label{sec:verwachte_resultaten}
Er wordt verwacht dat er een duidelijk verschil zal zijn tussen de frameworks en bibliotheken. Kubeflow zal een uitdaging vormen door de onduidelijke documentatie, hierbij zal worden onderzocht of een ander alternatief mogelijk beter is.
Het uiteindelijke resultaat is een rapport die de verschillende data zullen samenbrengen en conclusies trekt met betrekking tot de uitdaging van het lokaal uitvoeren van Kubeflow, rekening houdend met de migratieproblemen en documentatiekwesties. Daarnaast zal het rapport aanbevelingen bevatten voor mogelijke verbeteringen in documentatie en migratieprocedures. Het rapport kan eventueel een beter alternatief bieden dan Kubeflow voor het lokaal uitvoeren van machine learning pipelines, afhankelijk van de resultaten van de testen die gedaan werden.

%Hier beschrijf je welke resultaten je verwacht. Als je metingen en simulaties uitvoert, kan je hier al mock-ups maken van de grafieken samen met de verwachte conclusies. Benoem zeker al je assen en de onderdelen van de grafiek die je gaat gebruiken. Dit zorgt ervoor dat je concreet weet welk soort data je moet verzamelen en hoe je die moet meten.

%Wat heeft de doelgroep van je onderzoek aan het resultaat? Op welke manier zorgt jouw bachelorproef voor een meerwaarde?

%Hier beschrijf je wat je verwacht uit je onderzoek, met de motivatie waarom. Het is \textbf{niet} erg indien uit je onderzoek andere resultaten en conclusies vloeien dan dat je hier beschrijft: het is dan juist interessant om te onderzoeken waarom jouw hypothesen niet overeenkomen met de resultaten.